{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"NLP Experiments.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awBL-SgfiKHu","executionInfo":{"status":"ok","timestamp":1628634813877,"user_tz":-180,"elapsed":142352,"user":{"displayName":"עומר ליבוביץ","photoUrl":"","userId":"04478696710233760360"}},"outputId":"ff0420ba-4724-4f09-ea64-c3c9bc3287c3"},"source":["#!pip install flair"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting flair\n","  Downloading flair-0.8.0.post1-py3-none-any.whl (284 kB)\n","\u001b[K     |████████████████████████████████| 284 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n","Collecting torch<=1.7.1,>=1.5.0\n","  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n","\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n","Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[K     |████████████████████████████████| 981 kB 41.3 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n","Collecting deprecated>=1.2.4\n","  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n","Collecting ftfy\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 2.7 MB/s \n","\u001b[?25hCollecting janome\n","  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n","\u001b[K     |████████████████████████████████| 19.7 MB 1.2 MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.95\n","  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 24.6 MB/s \n","\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n","Collecting bpemb>=0.3.2\n","  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n","Collecting sqlitedict>=1.6.0\n","  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n","Collecting segtok>=1.5.7\n","  Downloading segtok-1.5.10.tar.gz (25 kB)\n","Collecting konoha<5.0.0,>=4.0.0\n","  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n","Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n","Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n","Collecting gdown==3.12.2\n","  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting transformers>=4.0.0\n","  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 69.1 MB/s \n","\u001b[?25hCollecting mpld3==0.3\n","  Downloading mpld3-0.3.tar.gz (788 kB)\n","\u001b[K     |████████████████████████████████| 788 kB 56.6 MB/s \n","\u001b[?25hCollecting huggingface-hub\n","  Downloading huggingface_hub-0.0.15-py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.1.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n","Collecting overrides<4.0.0,>=3.0.0\n","  Downloading overrides-3.1.0.tar.gz (11 kB)\n","Collecting importlib-metadata<4.0.0,>=3.7.0\n","  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n","Collecting requests\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 922 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.5.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.5.30)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 71.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 59.0 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 43.8 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n","Building wheels for collected packages: gdown, mpld3, overrides, segtok, sqlitedict, ftfy, langdetect\n","  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9705 sha256=2387c4b12f49f0574fd162aae054e37740904cbec2c89826a37ef8446ccac21f\n","  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116701 sha256=75b0d967c7ae777394267ae9eca58ed86a10e8200ed31d27fa2f6976b8c67bff\n","  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10188 sha256=27c41682628fc100734190b9ab4d84918a5efeacab57cfa7d081a14358dae042\n","  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=e6a46e45bc74700cc5278eb594bf40ab2dddd5ffe1a8de6019986a3aea7e087c\n","  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=2d2cb74791b31cfdbf528c7d07d6b3b46cc63393feef240833e64e6c0d614719\n","  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41934 sha256=86f93136bd2c08ed39f9c11396aad4cab0c4b4c9604442aa7549167785b1cf92\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993241 sha256=2d75be515ea7238f51b663381dcc94b13ddff2dbf587035fbbb0124864cc539a\n","  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n","Successfully built gdown mpld3 overrides segtok sqlitedict ftfy langdetect\n","Installing collected packages: requests, importlib-metadata, tokenizers, sentencepiece, sacremoses, pyyaml, overrides, huggingface-hub, transformers, torch, sqlitedict, segtok, mpld3, langdetect, konoha, janome, gdown, ftfy, deprecated, bpemb, flair\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.6.1\n","    Uninstalling importlib-metadata-4.6.1:\n","      Successfully uninstalled importlib-metadata-4.6.1\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 3.6.4\n","    Uninstalling gdown-3.6.4:\n","      Successfully uninstalled gdown-3.6.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.12 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pyyaml-5.4.1 requests-2.26.0 sacremoses-0.0.45 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 torch-1.7.1 transformers-4.9.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"CF-D_60siKHw","executionInfo":{"status":"error","timestamp":1628634819101,"user_tz":-180,"elapsed":5243,"user":{"displayName":"עומר ליבוביץ","photoUrl":"","userId":"04478696710233760360"}},"outputId":"3dbae5d1-9c14-4383-99c3-be167124ceb0"},"source":["import flair\n","from flair.datasets import CONLL_03\n","corpus: Corpus = flair.datasets.CONLL_03(base_path='resources/tasks')\n","\n","from flair.data import Corpus\n","from flair.datasets import CONLL_03\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n","from typing import List\n","\n","\n","# 1. get the corpus\n","corpus: Corpus = CONLL_03(base_path='resources/tasks')\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'ner'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","\n","# initialize embeddings\n","embedding_types: List[TokenEmbeddings] = [\n","\n","    # GloVe embeddings\n","    WordEmbeddings('glove'),\n","\n","    # contextual string embeddings, forward\n","    PooledFlairEmbeddings('news-forward', pooling='min'),\n","\n","    # contextual string embeddings, backward\n","    PooledFlairEmbeddings('news-backward', pooling='min'),\n","]\n","\n","embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n","# initialize sequence tagger\n","from flair.models import SequenceTagger\n","\n","tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n","                                        embeddings=embeddings,\n","                                        tag_dictionary=tag_dictionary,\n","                                        tag_type=tag_type)\n","\n","# initialize trainer\n","from flair.trainers import ModelTrainer\n","\n","trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n","\n","trainer.train(base_path='resources/taggers/example-ner',\n","              train_with_dev=True,  \n","              max_epochs=150,embeddings_storage_mode='gpu',checkpoint=False,monitor_train=False,monitor_test=True,\n","             save_final_model = False)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["2021-08-10 22:33:39,333 ----------------------------------------------------------------------------------------------------\n","2021-08-10 22:33:39,335 WARNING: CoNLL-03 dataset not found at \"resources/tasks/conll_03\".\n","2021-08-10 22:33:39,337 Instructions for obtaining the data can be found here: https://www.clips.uantwerpen.be/conll2003/ner/\"\n","2021-08-10 22:33:39,339 ----------------------------------------------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e77bb0ddd293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONLL_03\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONLL_03\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resources/tasks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/datasets/sequence_labeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, base_path, tag_to_bioes, in_memory, **corpusargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mdocument_separator_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"-DOCSTART-\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mcorpusargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         )\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/datasets/sequence_labeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_folder, column_format, train_file, test_file, dev_file, tag_to_bioes, column_delimiter, comment_symbol, encoding, document_separator_token, skip_first_line, in_memory, label_name_map, autofind_splits, **corpusargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# find train, dev and test files if not specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdev_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_file\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mfind_train_dev_test_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautofind_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# get train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/datasets/base.py\u001b[0m in \u001b[0;36mfind_train_dev_test_files\u001b[0;34m(data_folder, dev_file, test_file, train_file, autofind_splits)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# automatically identify train / test / dev files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mautofind_splits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_folder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuffixes_to_ignore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdisjoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resources/tasks/conll_03'"]}]},{"cell_type":"code","metadata":{"id":"xmNXIzO-iKHx"},"source":["import transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FD8vk2u1iKHy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCAyK87wiKHy","outputId":"8f4a5afe-e412-40ac-b687-066f01f9d8b2"},"source":["from flair.datasets import CONLL_03\n","corpus: Corpus = CONLL_03(base_path='resources/tasks')\n","\n","from flair.data import Corpus\n","from flair.datasets import CONLL_03\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n","from typing import List\n","\n","\n","# 1. get the corpus\n","corpus: Corpus = CONLL_03(base_path='resources/tasks')\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'ner'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","\n","# initialize embeddings\n","embedding_types: List[TokenEmbeddings] = [\n","\n","    # GloVe embeddings\n","    WordEmbeddings('glove'),\n","\n","    # contextual string embeddings, forward\n","    PooledFlairEmbeddings('news-forward', pooling='min'),\n","\n","    # contextual string embeddings, backward\n","    PooledFlairEmbeddings('news-backward', pooling='min'),\n","]\n","\n","embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n","# initialize sequence tagger\n","from taggerBF import SequenceTaggerBF\n","\n","tagger: SequenceTaggerBF = SequenceTaggerBF(hidden_size=256,\n","                                        embeddings=embeddings,\n","                                        tag_dictionary=tag_dictionary,\n","                                        tag_type=tag_type)\n","\n","# initialize trainer\n","from flair.trainers import ModelTrainer\n","\n","trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n","\n","trainer.train(base_path='resources/BFtaggers/example-ner',\n","              train_with_dev=True,  \n","              max_epochs=10,embeddings_storage_mode='gpu',checkpoint=False,monitor_train=True,monitor_test=True,\n","             save_final_model = False, mini_batch_size = 1)\n","\n","from flair.data import Corpus\n","from flair.datasets import CONLL_03_GERMAN\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n","from typing import List\n","\n","# 1. get the corpus\n","corpus: Corpus = CONLL_03_GERMAN(base_path='resources/tasks')\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'ner'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","\n","# initialize embeddings\n","embedding_types: List[TokenEmbeddings] = [\n","    WordEmbeddings('de'),\n","    PooledFlairEmbeddings('german-forward'),\n","    PooledFlairEmbeddings('german-backward'),\n","]\n","\n","embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n","\n","# initialize sequence tagger\n","from flair.models import SequenceTagger\n","\n","tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n","                                        embeddings=embeddings,\n","                                        tag_dictionary=tag_dictionary,\n","                                        tag_type=tag_type)\n","\n","# initialize trainer\n","from flair.trainers import ModelTrainer\n","\n","trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n","\n","trainer.train('resources/taggers/example-ner',\n","              train_with_dev=True,  \n","              max_epochs=150)\n","\n","from flair.data import Corpus\n","from flair.datasets import UniversalDependenciesCorpus\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n","from typing import List\n","\n","# 1. get the corpus\n","corpus: Corpus = UniversalDependenciesCorpus(base_path='/penn')\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'pos'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","\n","# initialize embeddings\n","embedding_types: List[TokenEmbeddings] = [\n","    WordEmbeddings('extvec'),\n","    FlairEmbeddings('news-forward'),\n","    FlairEmbeddings('news-backward'),\n","]\n","\n","embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n","\n","# initialize sequence tagger\n","from flair.models import SequenceTagger\n","\n","tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n","                                        embeddings=embeddings,\n","                                        tag_dictionary=tag_dictionary,\n","                                        tag_type=tag_type)\n","# initialize trainer\n","from flair.trainers import ModelTrainer\n","\n","trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n","\n","trainer.train('resources/taggers/example-pos',\n","              train_with_dev=True,  \n","              max_epochs=150)\n","\n","import logging\n","from pathlib import Path\n","from typing import List, Union, Optional, Callable, Dict\n","\n","import numpy as np\n","import torch\n","import torch.nn\n","import torch.nn.functional as F\n","from tabulate import tabulate\n","from torch.nn.parameter import Parameter\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","import flair.nn\n","from flair.data import Dictionary, Sentence, Token, Label, space_tokenizer\n","from flair.datasets import SentenceDataset, StringDataset\n","from flair.embeddings import TokenEmbeddings\n","from flair.file_utils import cached_path, unzip_file\n","from flair.training_utils import Metric, Result, store_embeddings\n","from butterfly import Butterfly\n","\n","\n","log = logging.getLogger(\"flair\")\n","\n","START_TAG: str = \"<START>\"\n","STOP_TAG: str = \"<STOP>\"\n","\n","\n","def to_scalar(var):\n","    return var.view(-1).detach().tolist()[0]\n","\n","\n","def argmax(vec):\n","    _, idx = torch.max(vec, 1)\n","    return to_scalar(idx)\n","\n","\n","def log_sum_exp(vec):\n","    max_score = vec[0, argmax(vec)]\n","    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n","    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n","\n","\n","def argmax_batch(vecs):\n","    _, idx = torch.max(vecs, 1)\n","    return idx\n","\n","\n","def log_sum_exp_batch(vecs):\n","    maxi = torch.max(vecs, 1)[0]\n","    maxi_bc = maxi[:, None].repeat(1, vecs.shape[1])\n","    recti_ = torch.log(torch.sum(torch.exp(vecs - maxi_bc), 1))\n","    return maxi + recti_\n","\n","\n","def pad_tensors(tensor_list):\n","    ml = max([x.shape[0] for x in tensor_list])\n","    shape = [len(tensor_list), ml] + list(tensor_list[0].shape[1:])\n","    template = torch.zeros(*shape, dtype=torch.long, device=flair.device)\n","    lens_ = [x.shape[0] for x in tensor_list]\n","    for i, tensor in enumerate(tensor_list):\n","        template[i, : lens_[i]] = tensor\n","    return template, lens_\n","\n","\n","class SequenceTaggerBF(flair.nn.Model):\n","    def __init__(\n","        self,\n","        hidden_size: int,\n","        embeddings: TokenEmbeddings,\n","        tag_dictionary: Dictionary,\n","        tag_type: str,\n","        use_crf: bool = True,\n","        use_rnn: bool = True,\n","        rnn_layers: int = 1,\n","        dropout: float = 0.0,\n","        word_dropout: float = 0.05,\n","        locked_dropout: float = 0.5,\n","        train_initial_hidden_state: bool = False,\n","        rnn_type: str = \"LSTM\",\n","        pickle_module: str = \"pickle\",\n","        beta: float = 1.0,\n","        loss_weights: Dict[str, float] = None,\n","    ):\n","        \"\"\"\n","        Initializes a SequenceTagger\n","        :param hidden_size: number of hidden states in RNN\n","        :param embeddings: word embeddings used in tagger\n","        :param tag_dictionary: dictionary of tags you want to predict\n","        :param tag_type: string identifier for tag type\n","        :param use_crf: if True use CRF decoder, else project directly to tag space\n","        :param use_rnn: if True use RNN layer, otherwise use word embeddings directly\n","        :param rnn_layers: number of RNN layers\n","        :param dropout: dropout probability\n","        :param word_dropout: word dropout probability\n","        :param locked_dropout: locked dropout probability\n","        :param train_initial_hidden_state: if True, trains initial hidden state of RNN\n","        :param beta: Parameter for F-beta score for evaluation and training annealing\n","        :param loss_weights: Dictionary of weights for classes (tags) for the loss function\n","        (if any tag's weight is unspecified it will default to 1.0)\n","        \"\"\"\n","\n","        super(SequenceTaggerBF, self).__init__()\n","        self.use_rnn = use_rnn\n","        self.hidden_size = hidden_size\n","        self.use_crf: bool = use_crf\n","        self.rnn_layers: int = rnn_layers\n","\n","        self.trained_epochs: int = 0\n","\n","        self.embeddings = embeddings\n","\n","        # set the dictionaries\n","        self.tag_dictionary: Dictionary = tag_dictionary\n","        self.tag_type: str = tag_type\n","        self.tagset_size: int = len(tag_dictionary)\n","\n","        self.beta = beta\n","\n","        self.weight_dict = loss_weights\n","        # Initialize the weight tensor\n","        if loss_weights is not None:\n","            n_classes = len(self.tag_dictionary)\n","            weight_list = [1. for i in range(n_classes)]\n","            for i, tag in enumerate(self.tag_dictionary.get_items()):\n","                if tag in loss_weights.keys():\n","                    weight_list[i] = loss_weights[tag]\n","            self.loss_weights = torch.FloatTensor(weight_list).to(flair.device)\n","        else:\n","            self.loss_weights = None\n","\n","        # initialize the network architecture\n","        self.nlayers: int = rnn_layers\n","        self.hidden_word = None\n","\n","        # dropouts\n","        self.use_dropout: float = dropout\n","        self.use_word_dropout: float = word_dropout\n","        self.use_locked_dropout: float = locked_dropout\n","\n","        self.pickle_module = pickle_module\n","\n","        if dropout > 0.0:\n","            self.dropout = torch.nn.Dropout(dropout)\n","\n","        if word_dropout > 0.0:\n","            self.word_dropout = flair.nn.WordDropout(word_dropout)\n","\n","        if locked_dropout > 0.0:\n","            self.locked_dropout = flair.nn.LockedDropout(locked_dropout)\n","\n","        rnn_input_dim: int = self.embeddings.embedding_length\n","\n","        self.relearn_embeddings: bool = True\n","\n","        if self.relearn_embeddings:\n","            self.embedding2nn = Butterfly(in_size=rnn_input_dim, out_size= rnn_input_dim, bias=False, complex=False,\n","                              tied_weight=False, increasing_stride=True, ortho_init=True)\n","            print (\"apperntly embedding\")\n","\n","        self.train_initial_hidden_state = train_initial_hidden_state\n","        self.bidirectional = True\n","        self.rnn_type = rnn_type\n","\n","        # bidirectional LSTM on top of embedding layer\n","        if self.use_rnn:\n","            num_directions = 2 if self.bidirectional else 1\n","\n","            if self.rnn_type in [\"LSTM\", \"GRU\"]:\n","\n","                self.rnn = getattr(torch.nn, self.rnn_type)(\n","                    rnn_input_dim,\n","                    hidden_size,\n","                    num_layers=self.nlayers,\n","                    dropout=0.0 if self.nlayers == 1 else 0.5,\n","                    bidirectional=True,\n","                    batch_first=True,\n","                )\n","                # Create initial hidden state and initialize it\n","                if self.train_initial_hidden_state:\n","                    self.hs_initializer = torch.nn.init.xavier_normal_\n","\n","                    self.lstm_init_h = Parameter(\n","                        torch.randn(self.nlayers * num_directions, self.hidden_size),\n","                        requires_grad=True,\n","                    )\n","\n","                    self.lstm_init_c = Parameter(\n","                        torch.randn(self.nlayers * num_directions, self.hidden_size),\n","                        requires_grad=True,\n","                    )\n","\n","                    # TODO: Decide how to initialize the hidden state variables\n","                    # self.hs_initializer(self.lstm_init_h)\n","                    # self.hs_initializer(self.lstm_init_c)\n","\n","            # final linear map to tag space\n","            self.linear = Butterfly(in_size=hidden_size * num_directions, out_size=len(tag_dictionary), bias=False, complex=False,\n","                              tied_weight=False, increasing_stride=True, ortho_init=True)\n","            print (\"if not else\")\n","        else:\n","            #self.linear = torch.nn.Linear(\n","            #    self.embeddings.embedding_length, len(tag_dictionary)\n","           # )\n","            self.linear = Butterfly(self.embeddings.embedding_length, out_size=len(tag_dictionary), bias=False, complex=False,\n","                              tied_weight=False, increasing_stride=True, ortho_init=True)\n","            print (\"else not if \")\n","\n","        if self.use_crf:\n","            self.transitions = torch.nn.Parameter(\n","                torch.randn(self.tagset_size, self.tagset_size)\n","            )\n","\n","            self.transitions.detach()[\n","                self.tag_dictionary.get_idx_for_item(START_TAG), :\n","            ] = -10000\n","\n","            self.transitions.detach()[\n","                :, self.tag_dictionary.get_idx_for_item(STOP_TAG)\n","            ] = -10000\n","\n","        self.to(flair.device)\n","\n","    def _get_state_dict(self):\n","        model_state = {\n","            \"state_dict\": self.state_dict(),\n","            \"embeddings\": self.embeddings,\n","            \"hidden_size\": self.hidden_size,\n","            \"train_initial_hidden_state\": self.train_initial_hidden_state,\n","            \"tag_dictionary\": self.tag_dictionary,\n","            \"tag_type\": self.tag_type,\n","            \"use_crf\": self.use_crf,\n","            \"use_rnn\": self.use_rnn,\n","            \"rnn_layers\": self.rnn_layers,\n","            \"use_word_dropout\": self.use_word_dropout,\n","            \"use_locked_dropout\": self.use_locked_dropout,\n","            \"rnn_type\": self.rnn_type,\n","            \"beta\": self.beta,\n","            \"weight_dict\": self.weight_dict,\n","        }\n","        return model_state\n","\n","    @staticmethod\n","    def _init_model_with_state_dict(state):\n","\n","        rnn_type = \"LSTM\" if \"rnn_type\" not in state.keys() else state[\"rnn_type\"]\n","        use_dropout = 0.0 if \"use_dropout\" not in state.keys() else state[\"use_dropout\"]\n","        use_word_dropout = (\n","            0.0 if \"use_word_dropout\" not in state.keys() else state[\"use_word_dropout\"]\n","        )\n","        use_locked_dropout = (\n","            0.0\n","            if \"use_locked_dropout\" not in state.keys()\n","            else state[\"use_locked_dropout\"]\n","        )\n","        train_initial_hidden_state = (\n","            False\n","            if \"train_initial_hidden_state\" not in state.keys()\n","            else state[\"train_initial_hidden_state\"]\n","        )\n","        beta = 1.0 if \"beta\" not in state.keys() else state[\"beta\"]\n","        weights = None if \"weight_dict\" not in state.keys() else state[\"weight_dict\"]\n","\n","        model = SequenceTaggerBF(\n","            hidden_size=state[\"hidden_size\"],\n","            embeddings=state[\"embeddings\"],\n","            tag_dictionary=state[\"tag_dictionary\"],\n","            tag_type=state[\"tag_type\"],\n","            use_crf=state[\"use_crf\"],\n","            use_rnn=state[\"use_rnn\"],\n","            rnn_layers=state[\"rnn_layers\"],\n","            dropout=use_dropout,\n","            word_dropout=use_word_dropout,\n","            locked_dropout=use_locked_dropout,\n","            train_initial_hidden_state=train_initial_hidden_state,\n","            rnn_type=rnn_type,\n","            beta=beta,\n","            loss_weights=weights,\n","        )\n","        model.load_state_dict(state[\"state_dict\"])\n","        return model\n","\n","    def predict(\n","        self,\n","        sentences: Union[List[Sentence], Sentence, List[str], str],\n","        mini_batch_size=32,\n","        embedding_storage_mode=\"none\",\n","        all_tag_prob: bool = False,\n","        verbose: bool = False,\n","        use_tokenizer: Union[bool, Callable[[str], List[Token]]] = space_tokenizer,\n","    ) -> List[Sentence]:\n","        \"\"\"\n","        Predict sequence tags for Named Entity Recognition task\n","        :param sentences: a Sentence or a string or a List of Sentence or a List of string.\n","        :param mini_batch_size: size of the minibatch, usually bigger is more rapid but consume more memory,\n","        up to a point when it has no more effect.\n","        :param embedding_storage_mode: 'none' for the minimum memory footprint, 'cpu' to store embeddings in Ram,\n","        'gpu' to store embeddings in GPU memory.\n","        :param all_tag_prob: True to compute the score for each tag on each token,\n","        otherwise only the score of the best tag is returned\n","        :param verbose: set to True to display a progress bar\n","        :param use_tokenizer: a custom tokenizer when string are provided (default is space based tokenizer).\n","        :return: List of Sentence enriched by the predicted tags\n","        \"\"\"\n","        with torch.no_grad():\n","            if not sentences:\n","                return sentences\n","\n","            if isinstance(sentences, Sentence) or isinstance(sentences, str):\n","                sentences = [sentences]\n","\n","            if (flair.device.type == \"cuda\") and embedding_storage_mode == \"cpu\":\n","                log.warning(\n","                    \"You are inferring on GPU with parameter 'embedding_storage_mode' set to 'cpu'.\"\n","                    \"This option will slow down your inference, usually 'none' (default value) \"\n","                    \"is a better choice.\"\n","                )\n","\n","            # reverse sort all sequences by their length\n","            rev_order_len_index = sorted(\n","                range(len(sentences)), key=lambda k: len(sentences[k]), reverse=True\n","            )\n","            original_order_index = sorted(\n","                range(len(rev_order_len_index)), key=lambda k: rev_order_len_index[k]\n","            )\n","\n","            reordered_sentences: List[Union[Sentence, str]] = [\n","                sentences[index] for index in rev_order_len_index\n","            ]\n","\n","            if isinstance(sentences[0], Sentence):\n","                # remove previous embeddings\n","                store_embeddings(reordered_sentences, \"none\")\n","                dataset = SentenceDataset(reordered_sentences)\n","            else:\n","                dataset = StringDataset(\n","                    reordered_sentences, use_tokenizer=use_tokenizer\n","                )\n","            dataloader = DataLoader(\n","                dataset=dataset, batch_size=mini_batch_size, collate_fn=lambda x: x\n","            )\n","\n","            if self.use_crf:\n","                transitions = self.transitions.detach().cpu().numpy()\n","            else:\n","                transitions = None\n","\n","            # progress bar for verbosity\n","            if verbose:\n","                dataloader = tqdm(dataloader)\n","\n","            results: List[Sentence] = []\n","            for i, batch in enumerate(dataloader):\n","\n","                if verbose:\n","                    dataloader.set_description(f\"Inferencing on batch {i}\")\n","                results += batch\n","                batch = self._filter_empty_sentences(batch)\n","                # stop if all sentences are empty\n","                if not batch:\n","                    continue\n","\n","                feature: torch.Tensor = self.forward(batch)\n","                tags, all_tags = self._obtain_labels(\n","                    feature=feature,\n","                    batch_sentences=batch,\n","                    transitions=transitions,\n","                    get_all_tags=all_tag_prob,\n","                )\n","\n","                for (sentence, sent_tags) in zip(batch, tags):\n","                    for (token, tag) in zip(sentence.tokens, sent_tags):\n","                        token.add_tag_label(self.tag_type, tag)\n","\n","                # all_tags will be empty if all_tag_prob is set to False, so the for loop will be avoided\n","                for (sentence, sent_all_tags) in zip(batch, all_tags):\n","                    for (token, token_all_tags) in zip(sentence.tokens, sent_all_tags):\n","                        token.add_tags_proba_dist(self.tag_type, token_all_tags)\n","\n","                # clearing token embeddings to save memory\n","                store_embeddings(batch, storage_mode=embedding_storage_mode)\n","\n","            results: List[Union[Sentence, str]] = [\n","                results[index] for index in original_order_index\n","            ]\n","            assert len(sentences) == len(results)\n","            return results\n","\n","    def evaluate(\n","        self,\n","        data_loader: DataLoader,\n","        out_path: Path = None,\n","        embedding_storage_mode: str = \"none\",\n","    ) -> (Result, float):\n","\n","        if type(out_path) == str:\n","            out_path = Path(out_path)\n","\n","        with torch.no_grad():\n","            eval_loss = 0\n","\n","            batch_no: int = 0\n","\n","            metric = Metric(\"Evaluation\", beta=self.beta)\n","\n","            lines: List[str] = []\n","\n","            if self.use_crf:\n","                transitions = self.transitions.detach().cpu().numpy()\n","            else:\n","                transitions = None\n","\n","            for batch in data_loader:\n","                batch_no += 1\n","\n","                with torch.no_grad():\n","                    features = self.forward(batch)\n","                    loss = self._calculate_loss(features, batch)\n","                    tags, _ = self._obtain_labels(\n","                        feature=features,\n","                        batch_sentences=batch,\n","                        transitions=transitions,\n","                        get_all_tags=False,\n","                    )\n","\n","                eval_loss += loss\n","\n","                for (sentence, sent_tags) in zip(batch, tags):\n","                    for (token, tag) in zip(sentence.tokens, sent_tags):\n","                        token: Token = token\n","                        token.add_tag(\"predicted\", tag.value, tag.score)\n","\n","                        # append both to file for evaluation\n","                        eval_line = \"{} {} {} {}\\n\".format(\n","                            token.text,\n","                            token.get_tag(self.tag_type).value,\n","                            tag.value,\n","                            tag.score,\n","                        )\n","                        lines.append(eval_line)\n","                    lines.append(\"\\n\")\n","\n","                for sentence in batch:\n","                    # make list of gold tags\n","                    gold_tags = [\n","                        (tag.tag, tag.text) for tag in sentence.get_spans(self.tag_type)\n","                    ]\n","                    # make list of predicted tags\n","                    predicted_tags = [\n","                        (tag.tag, tag.text) for tag in sentence.get_spans(\"predicted\")\n","                    ]\n","\n","                    # check for true positives, false positives and false negatives\n","                    for tag, prediction in predicted_tags:\n","                        if (tag, prediction) in gold_tags:\n","                            metric.add_tp(tag)\n","                        else:\n","                            metric.add_fp(tag)\n","\n","                    for tag, gold in gold_tags:\n","                        if (tag, gold) not in predicted_tags:\n","                            metric.add_fn(tag)\n","                        else:\n","                            metric.add_tn(tag)\n","\n","                store_embeddings(batch, embedding_storage_mode)\n","\n","            eval_loss /= batch_no\n","\n","            if out_path is not None:\n","                with open(out_path, \"w\", encoding=\"utf-8\") as outfile:\n","                    outfile.write(\"\".join(lines))\n","\n","            detailed_result = (\n","                f\"\\nMICRO_AVG: acc {metric.micro_avg_accuracy():.4f} - f1-score {metric.micro_avg_f_score():.4f}\"\n","                f\"\\nMACRO_AVG: acc {metric.macro_avg_accuracy():.4f} - f1-score {metric.macro_avg_f_score():.4f}\"\n","            )\n","            for class_name in metric.get_classes():\n","                detailed_result += (\n","                    f\"\\n{class_name:<10} tp: {metric.get_tp(class_name)} - fp: {metric.get_fp(class_name)} - \"\n","                    f\"fn: {metric.get_fn(class_name)} - tn: {metric.get_tn(class_name)} - precision: \"\n","                    f\"{metric.precision(class_name):.4f} - recall: {metric.recall(class_name):.4f} - \"\n","                    f\"accuracy: {metric.accuracy(class_name):.4f} - f1-score: \"\n","                    f\"{metric.f_score(class_name):.4f}\"\n","                )\n","\n","            result = Result(\n","                main_score=metric.micro_avg_f_score(),\n","                log_line=f\"{metric.precision():.4f}\\t{metric.recall():.4f}\\t{metric.micro_avg_f_score():.4f}\",\n","                log_header=\"PRECISION\\tRECALL\\tF1\",\n","                detailed_results=detailed_result,\n","            )\n","\n","            return result, eval_loss\n","\n","    def forward_loss(\n","        self, data_points: Union[List[Sentence], Sentence], sort=True\n","    ) -> torch.tensor:\n","        features = self.forward(data_points)\n","        return self._calculate_loss(features, data_points)\n","\n","    def forward(self, sentences: List[Sentence]):\n","\n","        self.embeddings.embed(sentences)\n","\n","        lengths: List[int] = [len(sentence.tokens) for sentence in sentences]\n","        longest_token_sequence_in_batch: int = max(lengths)\n","\n","        pre_allocated_zero_tensor = torch.zeros(\n","            self.embeddings.embedding_length * longest_token_sequence_in_batch,\n","            dtype=torch.float,\n","            device=flair.device,\n","        )\n","\n","        all_embs = list()\n","        for sentence in sentences:\n","            all_embs += [\n","                emb for token in sentence for emb in token.get_each_embedding()\n","            ]\n","            nb_padding_tokens = longest_token_sequence_in_batch - len(sentence)\n","\n","            if nb_padding_tokens > 0:\n","                t = pre_allocated_zero_tensor[\n","                    : self.embeddings.embedding_length * nb_padding_tokens\n","                ]\n","                all_embs.append(t)\n","\n","        sentence_tensor = torch.cat(all_embs).view(\n","            [\n","                len(sentences),\n","                longest_token_sequence_in_batch,\n","                self.embeddings.embedding_length,\n","            ]\n","        )\n","\n","        # --------------------------------------------------------------------\n","        # FF PART\n","        # --------------------------------------------------------------------\n","        if self.use_dropout > 0.0:\n","            sentence_tensor = self.dropout(sentence_tensor)\n","        if self.use_word_dropout > 0.0:\n","            sentence_tensor = self.word_dropout(sentence_tensor)\n","        if self.use_locked_dropout > 0.0:\n","            sentence_tensor = self.locked_dropout(sentence_tensor)\n","\n","        if self.relearn_embeddings:\n","            print (sentence_tensor.shape)\n","            sentence_tensor = self.embedding2nn(sentence_tensor)\n","\n","        if self.use_rnn:\n","            packed = torch.nn.utils.rnn.pack_padded_sequence(\n","                sentence_tensor, lengths, enforce_sorted=False, batch_first=True\n","            )\n","\n","            # if initial hidden state is trainable, use this state\n","            if self.train_initial_hidden_state:\n","                initial_hidden_state = [\n","                    self.lstm_init_h.unsqueeze(1).repeat(1, len(sentences), 1),\n","                    self.lstm_init_c.unsqueeze(1).repeat(1, len(sentences), 1),\n","                ]\n","                rnn_output, hidden = self.rnn(packed, initial_hidden_state)\n","            else:\n","                rnn_output, hidden = self.rnn(packed)\n","\n","            sentence_tensor, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n","                rnn_output, batch_first=True\n","            )\n","\n","            if self.use_dropout > 0.0:\n","                sentence_tensor = self.dropout(sentence_tensor)\n","            # word dropout only before LSTM - TODO: more experimentation needed\n","            # if self.use_word_dropout > 0.0:\n","            #     sentence_tensor = self.word_dropout(sentence_tensor)\n","            if self.use_locked_dropout > 0.0:\n","                sentence_tensor = self.locked_dropout(sentence_tensor)\n","        print (sentence_tensor.shape)\n","        print (sentence_tensor)\n","        features = self.linear(sentence_tensor)\n","\n","        return features\n","\n","    def _score_sentence(self, feats, tags, lens_):\n","\n","        start = torch.tensor(\n","            [self.tag_dictionary.get_idx_for_item(START_TAG)], device=flair.device\n","        )\n","        start = start[None, :].repeat(tags.shape[0], 1)\n","\n","        stop = torch.tensor(\n","            [self.tag_dictionary.get_idx_for_item(STOP_TAG)], device=flair.device\n","        )\n","        stop = stop[None, :].repeat(tags.shape[0], 1)\n","\n","        pad_start_tags = torch.cat([start, tags], 1)\n","        pad_stop_tags = torch.cat([tags, stop], 1)\n","\n","        for i in range(len(lens_)):\n","            pad_stop_tags[i, lens_[i] :] = self.tag_dictionary.get_idx_for_item(\n","                STOP_TAG\n","            )\n","\n","        score = torch.FloatTensor(feats.shape[0]).to(flair.device)\n","\n","        for i in range(feats.shape[0]):\n","            r = torch.LongTensor(range(lens_[i])).to(flair.device)\n","\n","            score[i] = torch.sum(\n","                self.transitions[\n","                    pad_stop_tags[i, : lens_[i] + 1], pad_start_tags[i, : lens_[i] + 1]\n","                ]\n","            ) + torch.sum(feats[i, r, tags[i, : lens_[i]]])\n","\n","        return score\n","\n","    def _calculate_loss(\n","        self, features: torch.tensor, sentences: List[Sentence]\n","    ) -> float:\n","\n","        lengths: List[int] = [len(sentence.tokens) for sentence in sentences]\n","\n","        tag_list: List = []\n","        for s_id, sentence in enumerate(sentences):\n","            # get the tags in this sentence\n","            tag_idx: List[int] = [\n","                self.tag_dictionary.get_idx_for_item(token.get_tag(self.tag_type).value)\n","                for token in sentence\n","            ]\n","            # add tags as tensor\n","            tag = torch.tensor(tag_idx, device=flair.device)\n","            tag_list.append(tag)\n","\n","        if self.use_crf:\n","            # pad tags if using batch-CRF decoder\n","            tags, _ = pad_tensors(tag_list)\n","\n","            forward_score = self._forward_alg(features, lengths)\n","            gold_score = self._score_sentence(features, tags, lengths)\n","            score = forward_score - gold_score\n","            return score.mean()\n","        else:\n","            score = 0\n","            for sentence_feats, sentence_tags, sentence_length in zip(\n","                features, tag_list, lengths\n","            ):\n","                sentence_feats = sentence_feats[:sentence_length]\n","                score += torch.nn.functional.cross_entropy(\n","                    sentence_feats, sentence_tags, weight=self.loss_weights\n","                )\n","            score /= len(features)\n","            return score\n","    def _obtain_labels(\n","        self,\n","        feature: torch.Tensor,\n","        batch_sentences: List[Sentence],\n","        transitions: Optional[np.ndarray],\n","        get_all_tags: bool,\n","    ) -> (List[List[Label]], List[List[List[Label]]]):\n","        \"\"\"\n","        Returns a tuple of two lists:\n","         - The first list corresponds to the most likely `Label` per token in each sentence.\n","         - The second list contains a probability distribution over all `Labels` for each token\n","           in a sentence for all sentences.\n","        \"\"\"\n","\n","        lengths: List[int] = [len(sentence.tokens) for sentence in batch_sentences]\n","\n","        tags = []\n","        all_tags = []\n","        feature = feature.cpu()\n","        if self.use_crf:\n","            feature = feature.numpy()\n","        else:\n","            for index, length in enumerate(lengths):\n","                feature[index, length:] = 0\n","            softmax_batch = F.softmax(feature, dim=2).cpu()\n","            scores_batch, prediction_batch = torch.max(softmax_batch, dim=2)\n","            feature = zip(softmax_batch, scores_batch, prediction_batch)\n","\n","        for feats, length in zip(feature, lengths):\n","            if self.use_crf:\n","                confidences, tag_seq, scores = self._viterbi_decode(\n","                    feats=feats[:length],\n","                    transitions=transitions,\n","                    all_scores=get_all_tags,\n","                )\n","            else:\n","                softmax, score, prediction = feats\n","                confidences = score[:length].tolist()\n","                tag_seq = prediction[:length].tolist()\n","                scores = softmax[:length].tolist()\n","\n","            tags.append(\n","                [\n","                    Label(self.tag_dictionary.get_item_for_index(tag), conf)\n","                    for conf, tag in zip(confidences, tag_seq)\n","                ]\n","            )\n","\n","            if get_all_tags:\n","                all_tags.append(\n","                    [\n","                        [\n","                            Label(\n","                                self.tag_dictionary.get_item_for_index(score_id), score\n","                            )\n","                            for score_id, score in enumerate(score_dist)\n","                        ]\n","                        for score_dist in scores\n","                    ]\n","                )\n","\n","        return tags, all_tags\n","\n","    @staticmethod\n","    def _softmax(x, axis):\n","        # reduce raw values to avoid NaN during exp\n","        x_norm = x - x.max(axis=axis, keepdims=True)\n","        y = np.exp(x_norm)\n","        return y / y.sum(axis=axis, keepdims=True)\n","\n","    def _viterbi_decode(\n","        self, feats: np.ndarray, transitions: np.ndarray, all_scores: bool\n","    ):\n","        id_start = self.tag_dictionary.get_idx_for_item(START_TAG)\n","        id_stop = self.tag_dictionary.get_idx_for_item(STOP_TAG)\n","\n","        backpointers = np.empty(shape=(feats.shape[0], self.tagset_size), dtype=np.int_)\n","        backscores = np.empty(\n","            shape=(feats.shape[0], self.tagset_size), dtype=np.float32\n","        )\n","\n","        init_vvars = np.expand_dims(\n","            np.repeat(-10000.0, self.tagset_size), axis=0\n","        ).astype(np.float32)\n","        init_vvars[0][id_start] = 0\n","\n","        forward_var = init_vvars\n","        for index, feat in enumerate(feats):\n","            # broadcasting will do the job of reshaping and is more efficient than calling repeat\n","            next_tag_var = forward_var + transitions\n","            bptrs_t = next_tag_var.argmax(axis=1)\n","            viterbivars_t = next_tag_var[np.arange(bptrs_t.shape[0]), bptrs_t]\n","            forward_var = viterbivars_t + feat\n","            backscores[index] = forward_var\n","            forward_var = forward_var[np.newaxis, :]\n","            backpointers[index] = bptrs_t\n","\n","        terminal_var = forward_var.squeeze() + transitions[id_stop]\n","        terminal_var[id_stop] = -10000.0\n","        terminal_var[id_start] = -10000.0\n","        best_tag_id = terminal_var.argmax()\n","\n","        best_path = [best_tag_id]\n","        for bptrs_t in reversed(backpointers):\n","            best_tag_id = bptrs_t[best_tag_id]\n","            best_path.append(best_tag_id)\n","\n","        start = best_path.pop()\n","        assert start == id_start\n","        best_path.reverse()\n","\n","        best_scores_softmax = self._softmax(backscores, axis=1)\n","        best_scores_np = np.max(best_scores_softmax, axis=1)\n","\n","        # default value\n","        all_scores_np = np.zeros(0, dtype=np.float64)\n","        if all_scores:\n","            all_scores_np = best_scores_softmax\n","            for index, (tag_id, tag_scores) in enumerate(zip(best_path, all_scores_np)):\n","                if type(tag_id) != int and tag_id.item() != tag_scores.argmax():\n","                    swap_index_score = tag_scores.argmax()\n","                    (\n","                        all_scores_np[index][tag_id.item()],\n","                        all_scores_np[index][swap_index_score],\n","                    ) = (\n","                        all_scores_np[index][swap_index_score],\n","                        all_scores_np[index][tag_id.item()],\n","                    )\n","                elif type(tag_id) == int and tag_id != tag_scores.argmax():\n","                    swap_index_score = tag_scores.argmax()\n","                    (\n","                        all_scores_np[index][tag_id],\n","                        all_scores_np[index][swap_index_score],\n","                    ) = (\n","                        all_scores_np[index][swap_index_score],\n","                        all_scores_np[index][tag_id],\n","                    )\n","\n","        return best_scores_np.tolist(), best_path, all_scores_np.tolist()\n","\n","    def _forward_alg(self, feats, lens_):\n","\n","        init_alphas = torch.FloatTensor(self.tagset_size).fill_(-10000.0)\n","        init_alphas[self.tag_dictionary.get_idx_for_item(START_TAG)] = 0.0\n","\n","        forward_var = torch.zeros(\n","            feats.shape[0],\n","            feats.shape[1] + 1,\n","            feats.shape[2],\n","            dtype=torch.float,\n","            device=flair.device,\n","        )\n","\n","        forward_var[:, 0, :] = init_alphas[None, :].repeat(feats.shape[0], 1)\n","\n","        transitions = self.transitions.view(\n","            1, self.transitions.shape[0], self.transitions.shape[1]\n","        ).repeat(feats.shape[0], 1, 1)\n","\n","        for i in range(feats.shape[1]):\n","            emit_score = feats[:, i, :]\n","\n","            tag_var = (\n","                emit_score[:, :, None].repeat(1, 1, transitions.shape[2])\n","                + transitions\n","                + forward_var[:, i, :][:, :, None]\n","                .repeat(1, 1, transitions.shape[2])\n","                .transpose(2, 1)\n","            )\n","\n","            max_tag_var, _ = torch.max(tag_var, dim=2)\n","\n","            tag_var = tag_var - max_tag_var[:, :, None].repeat(\n","                1, 1, transitions.shape[2]\n","            )\n","\n","            agg_ = torch.log(torch.sum(torch.exp(tag_var), dim=2))\n","\n","            cloned = forward_var.clone()\n","            cloned[:, i + 1, :] = max_tag_var + agg_\n","\n","            forward_var = cloned\n","\n","        forward_var = forward_var[range(forward_var.shape[0]), lens_, :]\n","\n","        terminal_var = forward_var + self.transitions[\n","            self.tag_dictionary.get_idx_for_item(STOP_TAG)\n","        ][None, :].repeat(forward_var.shape[0], 1)\n","        alpha = log_sum_exp_batch(terminal_var)\n","        return alpha\n","    @staticmethod\n","    def _filter_empty_sentences(sentences: List[Sentence]) -> List[Sentence]:\n","        filtered_sentences = [sentence for sentence in sentences if sentence.tokens]\n","        if len(sentences) != len(filtered_sentences):\n","            log.warning(\n","                f\"Ignore {len(sentences) - len(filtered_sentences)} sentence(s) with no tokens.\"\n","            )\n","        return filtered_sentences\n","\n","    @staticmethod\n","    def _filter_empty_string(texts: List[str]) -> List[str]:\n","        filtered_texts = [text for text in texts if text]\n","        if len(texts) != len(filtered_texts):\n","            log.warning(\n","                f\"Ignore {len(texts) - len(filtered_texts)} string(s) with no tokens.\"\n","            )\n","        return filtered_texts\n","    @staticmethod\n","    def _fetch_model(model_name) -> str:\n","        model_map = {}\n","        aws_resource_path_v04 = (\n","            \"https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4\"\n","        )\n","\n","        model_map[\"ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"NER-conll03-english\", \"en-ner-conll03-v0.4.pt\"]\n","        )\n","\n","        model_map[\"ner-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"NER-conll03--h256-l1-b32-p3-0.5-%2Bglove%2Bnews-forward-fast%2Bnews-backward-fast-normal-locked0.5-word0.05--release_4\",\n","                \"en-ner-fast-conll03-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"ner-ontonotes\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-ner-ontonotes-0\",\n","                \"en-ner-ontonotes-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"ner-ontonotes-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-ner-ontonotes-fast-0\",\n","                \"en-ner-ontonotes-fast-v0.4.pt\",\n","            ]\n","        )\n","        for key in [\"ner-multi\", \"multi-ner\"]:\n","            model_map[key] = \"/\".join(\n","                [\n","                    aws_resource_path_v04,\n","                    \"release-quadner-512-l2-multi-embed\",\n","                    \"quadner-large.pt\",\n","                ]\n","            )\n","        for key in [\"ner-multi-fast\", \"multi-ner-fast\"]:\n","            model_map[key] = \"/\".join(\n","                [aws_resource_path_v04, \"NER-multi-fast\", \"ner-multi-fast.pt\"]\n","            )\n","        for key in [\"ner-multi-fast-learn\", \"multi-ner-fast-learn\"]:\n","            model_map[key] = \"/\".join(\n","                [\n","                    aws_resource_path_v04,\n","                    \"NER-multi-fast-evolve\",\n","                    \"ner-multi-fast-learn.pt\",\n","                ]\n","            )\n","        model_map[\"pos\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"POS-ontonotes--h256-l1-b32-p3-0.5-%2Bglove%2Bnews-forward%2Bnews-backward-normal-locked0.5-word0.05--v0.4_0\",\n","                \"en-pos-ontonotes-v0.4.pt\",\n","            ]\n","        )\n","\n","        model_map[\"pos-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-pos-fast-0\",\n","                \"en-pos-ontonotes-fast-v0.4.pt\",\n","            ]\n","        )\n","        for key in [\"pos-multi\", \"multi-pos\"]:\n","            model_map[key] = \"/\".join(\n","                [\n","                    aws_resource_path_v04,\n","                    \"release-dodekapos-512-l2-multi\",\n","                    \"pos-multi-v0.1.pt\",\n","                ]\n","            )\n","        for key in [\"pos-multi-fast\", \"multi-pos-fast\"]:\n","            model_map[key] = \"/\".join(\n","                [aws_resource_path_v04, \"UPOS-multi-fast\", \"pos-multi-fast.pt\"]\n","            )\n","        model_map[\"frame\"] = \"/\".join(\n","            [aws_resource_path_v04, \"release-frame-1\", \"en-frame-ontonotes-v0.4.pt\"]\n","        )\n","\n","        model_map[\"frame-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-frame-fast-0\",\n","                \"en-frame-ontonotes-fast-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"chunk\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"NP-conll2000--h256-l1-b32-p3-0.5-%2Bnews-forward%2Bnews-backward-normal-locked0.5-word0.05--v0.4_0\",\n","                \"en-chunk-conll2000-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"chunk-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-chunk-fast-0\",\n","                \"en-chunk-conll2000-fast-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"da-pos\"] = \"/\".join(\n","            [aws_resource_path_v04, \"POS-danish\", \"da-pos-v0.1.pt\"]\n","        )\n","\n","        model_map[\"da-ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"NER-danish\", \"da-ner-v0.1.pt\"]\n","        )\n","\n","        model_map[\"de-pos\"] = \"/\".join(\n","            [aws_resource_path_v04, \"release-de-pos-0\", \"de-pos-ud-hdt-v0.4.pt\"]\n","        )\n","        model_map[\"de-pos-fine-grained\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"POS-fine-grained-german-tweets\",\n","                \"de-pos-twitter-v0.1.pt\",\n","            ]\n","        )\n","        model_map[\"de-ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"release-de-ner-0\", \"de-ner-conll03-v0.4.pt\"]\n","        )\n","\n","        model_map[\"de-ner-germeval\"] = \"/\".join(\n","            [aws_resource_path_v04, \"NER-germeval\", \"de-ner-germeval-0.4.1.pt\"]\n","        )\n","\n","        model_map[\"fr-ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"release-fr-ner-0\", \"fr-ner-wikiner-0.4.pt\"]\n","        )\n","        model_map[\"nl-ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"NER-conll2002-dutch\", \"nl-ner-conll02-v0.1.pt\"]\n","        )\n","        model_map[\"ml-pos\"] = \"https://raw.githubusercontent.com/qburst/models-repository/master/FlairMalayalamModels/malayalam-upos-model.pt\"\n","        model_map[\"ml-xpos\"] = \"https://raw.githubusercontent.com/qburst/models-repository/master/FlairMalayalamModels/malayalam-xpos-model.pt\"\n","\n","        cache_dir = Path(\"models\")\n","        if model_name in model_map:\n","            model_name = cached_path(model_map[model_name], cache_dir=cache_dir)\n","        # the historical German taggers by the @redewiegergabe project\n","        if model_name == \"de-historic-indirect\":\n","            model_file = Path(flair.cache_root)  / cache_dir / 'indirect' / 'final-model.pt'\n","            if not model_file.exists():\n","                cached_path('http://www.redewiedergabe.de/models/indirect.zip', cache_dir=cache_dir)\n","                unzip_file(Path(flair.cache_root)  / cache_dir / 'indirect.zip', Path(flair.cache_root)  / cache_dir)\n","            model_name = str(Path(flair.cache_root)  / cache_dir / 'indirect' / 'final-model.pt')\n","\n","        if model_name == \"de-historic-direct\":\n","            model_file = Path(flair.cache_root)  / cache_dir / 'direct' / 'final-model.pt'\n","            if not model_file.exists():\n","                cached_path('http://www.redewiedergabe.de/models/direct.zip', cache_dir=cache_dir)\n","                unzip_file(Path(flair.cache_root)  / cache_dir / 'direct.zip', Path(flair.cache_root)  / cache_dir)\n","            model_name = str(Path(flair.cache_root)  / cache_dir / 'direct' / 'final-model.pt')\n","\n","        if model_name == \"de-historic-reported\":\n","            model_file = Path(flair.cache_root)  / cache_dir / 'reported' / 'final-model.pt'\n","            if not model_file.exists():\n","                cached_path('http://www.redewiedergabe.de/models/reported.zip', cache_dir=cache_dir)\n","                unzip_file(Path(flair.cache_root)  / cache_dir / 'reported.zip', Path(flair.cache_root)  / cache_dir)\n","            model_name = str(Path(flair.cache_root)  / cache_dir / 'reported' / 'final-model.pt')\n","\n","        if model_name == \"de-historic-free-indirect\":\n","            model_file = Path(flair.cache_root)  / cache_dir / 'freeIndirect' / 'final-model.pt'\n","            if not model_file.exists():\n","                cached_path('http://www.redewiedergabe.de/models/freeIndirect.zip', cache_dir=cache_dir)\n","                unzip_file(Path(flair.cache_root)  / cache_dir / 'freeIndirect.zip', Path(flair.cache_root)  / cache_dir)\n","            model_name = str(Path(flair.cache_root)  / cache_dir / 'freeIndirect' / 'final-model.pt')\n","\n","        return model_name\n","    def get_transition_matrix(self):\n","        data = []\n","        for to_idx, row in enumerate(self.transitions):\n","            for from_idx, column in enumerate(row):\n","                row = [\n","                    self.tag_dictionary.get_item_for_index(from_idx),\n","                    self.tag_dictionary.get_item_for_index(to_idx),\n","                    column.item(),\n","                ]\n","                data.append(row)\n","            data.append([\"----\"])\n","        print(tabulate(data, headers=[\"FROM\", \"TO\", \"SCORE\"]))\n","    def __str__(self):\n","        return super(flair.nn.Model, self).__str__().rstrip(')') + \\\n","               f'  (beta): {self.beta}\\n' + \\\n","               f'  (weights): {self.weight_dict}\\n' + \\\n","               f'  (weight_tensor) {self.loss_weights}\\n)'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","WARNING: CoNLL-03 dataset not found at \"resources/tasks/conll_03\".\n","Instructions for obtaining the data can be found here: https://www.clips.uantwerpen.be/conll2003/ner/\"\n","----------------------------------------------------------------------------------------------------\n"],"name":"stderr"},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'resources/tasks/conll_03'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-6936fadaa756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONLL_03\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONLL_03\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resources/tasks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONLL_03\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/flair/datasets/sequence_labeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, base_path, tag_to_bioes, in_memory, **corpusargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mdocument_separator_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"-DOCSTART-\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mcorpusargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         )\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/flair/datasets/sequence_labeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_folder, column_format, train_file, test_file, dev_file, tag_to_bioes, column_delimiter, comment_symbol, encoding, document_separator_token, skip_first_line, in_memory, label_name_map, autofind_splits, **corpusargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# find train, dev and test files if not specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdev_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_file\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mfind_train_dev_test_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautofind_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# get train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/flair/datasets/base.py\u001b[0m in \u001b[0;36mfind_train_dev_test_files\u001b[0;34m(data_folder, dev_file, test_file, train_file, autofind_splits)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# automatically identify train / test / dev files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mautofind_splits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_folder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuffixes_to_ignore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdisjoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resources/tasks/conll_03'"]}]},{"cell_type":"code","metadata":{"id":"lLSyCfJSiKH5","outputId":"592adb59-1dfa-4466-f9c9-249e35d5aeba"},"source":["'''Some helper functions for PyTorch, including:\n","    - get_mean_and_std: calculate the mean and std value of dataset.\n","    - msr_init: net parameter initialization.\n","    - progress_bar: progress bar mimic xlua.progress.\n","'''\n","import os\n","import sys\n","import time\n","import math\n","\n","import torch.nn as nn\n","import torch.nn.init as init\n","\n","\n","def get_mean_and_std(dataset):\n","    '''Compute the mean and std value of dataset.'''\n","    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n","    mean = torch.zeros(3)\n","    std = torch.zeros(3)\n","    print('==> Computing mean and std..')\n","    for inputs, targets in dataloader:\n","        for i in range(3):\n","            mean[i] += inputs[:,i,:,:].mean()\n","            std[i] += inputs[:,i,:,:].std()\n","    mean.div_(len(dataset))\n","    std.div_(len(dataset))\n","    return mean, std\n","\n","def init_params(net):\n","    '''Init layer parameters.'''\n","    for m in net.modules():\n","        if isinstance(m, nn.Conv2d):\n","            init.kaiming_normal(m.weight, mode='fan_out')\n","            if m.bias:\n","                init.constant(m.bias, 0)\n","        elif isinstance(m, nn.BatchNorm2d):\n","            init.constant(m.weight, 1)\n","            init.constant(m.bias, 0)\n","        elif isinstance(m, nn.Linear):\n","            init.normal(m.weight, std=1e-3)\n","            if m.bias:\n","                init.constant(m.bias, 0)\n","\n","\n","_, term_width = os.popen('stty size', 'r').read().split()\n","term_width = int(term_width)\n","\n","TOTAL_BAR_LENGTH = 65.\n","last_time = time.time()\n","begin_time = last_time\n","def progress_bar(current, total, msg=None):\n","    global last_time, begin_time\n","    if current == 0:\n","        begin_time = time.time()  # Reset for new bar.\n","\n","    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n","    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n","\n","    sys.stdout.write(' [')\n","    for i in range(cur_len):\n","        sys.stdout.write('=')\n","    sys.stdout.write('>')\n","    for i in range(rest_len):\n","        sys.stdout.write('.')\n","    sys.stdout.write(']')\n","\n","    cur_time = time.time()\n","    step_time = cur_time - last_time\n","    last_time = cur_time\n","    tot_time = cur_time - begin_time\n","\n","    L = []\n","    L.append('  Step: %s' % format_time(step_time))\n","    L.append(' | Tot: %s' % format_time(tot_time))\n","    if msg:\n","        L.append(' | ' + msg)\n","\n","    msg = ''.join(L)\n","    sys.stdout.write(msg)\n","    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n","        sys.stdout.write(' ')\n","\n","    # Go back to the center of the bar.\n","    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n","        sys.stdout.write('\\b')\n","    sys.stdout.write(' %d/%d ' % (current+1, total))\n","\n","    if current < total-1:\n","        sys.stdout.write('\\r')\n","    else:\n","        sys.stdout.write('\\n')\n","    sys.stdout.flush()\n","\n","def format_time(seconds):\n","    days = int(seconds / 3600/24)\n","    seconds = seconds - days*3600*24\n","    hours = int(seconds / 3600)\n","    seconds = seconds - hours*3600\n","    minutes = int(seconds / 60)\n","    seconds = seconds - minutes*60\n","    secondsf = int(seconds)\n","    seconds = seconds - secondsf\n","    millis = int(seconds*1000)\n","\n","    f = ''\n","    i = 1\n","    if days > 0:\n","        f += str(days) + 'D'\n","        i += 1\n","    if hours > 0 and i <= 2:\n","        f += str(hours) + 'h'\n","        i += 1\n","    if minutes > 0 and i <= 2:\n","        f += str(minutes) + 'm'\n","        i += 1\n","    if secondsf > 0 and i <= 2:\n","        f += str(secondsf) + 's'\n","        i += 1\n","    if millis > 0 and i <= 2:\n","        f += str(millis) + 'ms'\n","        i += 1\n","    if f == '':\n","        f = '0ms'\n","    return f"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"not enough values to unpack (expected 2, got 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-99a36488fd28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stty size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mterm_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"]}]},{"cell_type":"code","metadata":{"id":"AQ9HEsgXiKH7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZouigFQiKH7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6sixDVqoiKH7"},"source":["from flair.datasets import CONLL_03\n","corpus: Corpus = CONLL_03(base_path='resources/tasks')\n","\n","from flair.data import Corpus\n","from flair.datasets import CONLL_03\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n","from typing import List\n","\n","\n","# 1. get the corpus\n","corpus: Corpus = CONLL_03(base_path='resources/tasks')\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'ner'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","\n","# initialize embeddings\n","embedding_types: List[TokenEmbeddings] = [\n","\n","    # GloVe embeddings\n","    WordEmbeddings('glove'),\n","\n","    # contextual string embeddings, forward\n","    PooledFlairEmbeddings('news-forward', pooling='min'),\n","\n","    # contextual string embeddings, backward\n","    PooledFlairEmbeddings('news-backward', pooling='min'),\n","]\n","\n","embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n","# initialize sequence tagger\n","from taggerBF import SequenceTaggerBF\n","\n","tagger: SequenceTaggerBF = SequenceTaggerBF(hidden_size=256,\n","                                        embeddings=embeddings,\n","                                        tag_dictionary=tag_dictionary,\n","                                        tag_type=tag_type)\n","\n","# initialize trainer\n","from flair.trainers import ModelTrainer\n","\n","trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n","\n","trainer.train(base_path='resources/BFtaggers/example-ner',\n","              train_with_dev=True,  \n","              max_epochs=10,embeddings_storage_mode='gpu',checkpoint=False,monitor_train=True,monitor_test=True,\n","             save_final_model = False, mini_batch_size = 1)\n","\n","from flair.data import Corpus\n","from flair.datasets import CONLL_03_GERMAN\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n","from typing import List\n","\n","# 1. get the corpus\n","corpus: Corpus = CONLL_03_GERMAN(base_path='resources/tasks')\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'ner'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","\n","# initialize embeddings\n","embedding_types: List[TokenEmbeddings] = [\n","    WordEmbeddings('de'),\n","    PooledFlairEmbeddings('german-forward'),\n","    PooledFlairEmbeddings('german-backward'),\n","]\n","\n","embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n","\n","# initialize sequence tagger\n","from flair.models import SequenceTagger\n","\n","tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n","                                        embeddings=embeddings,\n","                                        tag_dictionary=tag_dictionary,\n","                                        tag_type=tag_type)\n","\n","# initialize trainer\n","from flair.trainers import ModelTrainer\n","\n","trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n","\n","trainer.train('resources/taggers/example-ner',\n","              train_with_dev=True,  \n","              max_epochs=150)\n","\n","from flair.data import Corpus\n","from flair.datasets import UniversalDependenciesCorpus\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n","from typing import List\n","\n","# 1. get the corpus\n","corpus: Corpus = UniversalDependenciesCorpus(base_path='/penn')\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'pos'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","\n","# initialize embeddings\n","embedding_types: List[TokenEmbeddings] = [\n","    WordEmbeddings('extvec'),\n","    FlairEmbeddings('news-forward'),\n","    FlairEmbeddings('news-backward'),\n","]\n","\n","embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n","\n","# initialize sequence tagger\n","from flair.models import SequenceTagger\n","\n","tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n","                                        embeddings=embeddings,\n","                                        tag_dictionary=tag_dictionary,\n","                                        tag_type=tag_type)\n","# initialize trainer\n","from flair.trainers import ModelTrainer\n","\n","trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n","\n","trainer.train('resources/taggers/example-pos',\n","              train_with_dev=True,  \n","              max_epochs=150)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ApJE2xatiKH8","outputId":"3464a604-d57b-4031-de49-669161ee5bae"},"source":["import logging\n","from pathlib import Path\n","from typing import List, Union, Optional, Callable, Dict\n","\n","import numpy as np\n","import torch\n","import torch.nn\n","import torch.nn.functional as F\n","from tabulate import tabulate\n","from torch.nn.parameter import Parameter\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","import flair.nn\n","from flair.data import Dictionary, Sentence, Token, Label, space_tokenizer\n","from flair.datasets import SentenceDataset, StringDataset\n","from flair.embeddings import TokenEmbeddings\n","from flair.file_utils import cached_path, unzip_file\n","from flair.training_utils import Metric, Result, store_embeddings\n","from butterfly import Butterfly\n","\n","\n","log = logging.getLogger(\"flair\")\n","\n","START_TAG: str = \"<START>\"\n","STOP_TAG: str = \"<STOP>\"\n","\n","\n","def to_scalar(var):\n","    return var.view(-1).detach().tolist()[0]\n","\n","\n","def argmax(vec):\n","    _, idx = torch.max(vec, 1)\n","    return to_scalar(idx)\n","\n","\n","def log_sum_exp(vec):\n","    max_score = vec[0, argmax(vec)]\n","    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n","    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n","\n","\n","def argmax_batch(vecs):\n","    _, idx = torch.max(vecs, 1)\n","    return idx\n","\n","\n","def log_sum_exp_batch(vecs):\n","    maxi = torch.max(vecs, 1)[0]\n","    maxi_bc = maxi[:, None].repeat(1, vecs.shape[1])\n","    recti_ = torch.log(torch.sum(torch.exp(vecs - maxi_bc), 1))\n","    return maxi + recti_\n","\n","\n","def pad_tensors(tensor_list):\n","    ml = max([x.shape[0] for x in tensor_list])\n","    shape = [len(tensor_list), ml] + list(tensor_list[0].shape[1:])\n","    template = torch.zeros(*shape, dtype=torch.long, device=flair.device)\n","    lens_ = [x.shape[0] for x in tensor_list]\n","    for i, tensor in enumerate(tensor_list):\n","        template[i, : lens_[i]] = tensor\n","    return template, lens_\n","\n","\n","class SequenceTaggerBF(flair.nn.Model):\n","    def __init__(\n","        self,\n","        hidden_size: int,\n","        embeddings: TokenEmbeddings,\n","        tag_dictionary: Dictionary,\n","        tag_type: str,\n","        use_crf: bool = True,\n","        use_rnn: bool = True,\n","        rnn_layers: int = 1,\n","        dropout: float = 0.0,\n","        word_dropout: float = 0.05,\n","        locked_dropout: float = 0.5,\n","        train_initial_hidden_state: bool = False,\n","        rnn_type: str = \"LSTM\",\n","        pickle_module: str = \"pickle\",\n","        beta: float = 1.0,\n","        loss_weights: Dict[str, float] = None,\n","    ):\n","        \"\"\"\n","        Initializes a SequenceTagger\n","        :param hidden_size: number of hidden states in RNN\n","        :param embeddings: word embeddings used in tagger\n","        :param tag_dictionary: dictionary of tags you want to predict\n","        :param tag_type: string identifier for tag type\n","        :param use_crf: if True use CRF decoder, else project directly to tag space\n","        :param use_rnn: if True use RNN layer, otherwise use word embeddings directly\n","        :param rnn_layers: number of RNN layers\n","        :param dropout: dropout probability\n","        :param word_dropout: word dropout probability\n","        :param locked_dropout: locked dropout probability\n","        :param train_initial_hidden_state: if True, trains initial hidden state of RNN\n","        :param beta: Parameter for F-beta score for evaluation and training annealing\n","        :param loss_weights: Dictionary of weights for classes (tags) for the loss function\n","        (if any tag's weight is unspecified it will default to 1.0)\n","        \"\"\"\n","\n","        super(SequenceTaggerBF, self).__init__()\n","        self.use_rnn = use_rnn\n","        self.hidden_size = hidden_size\n","        self.use_crf: bool = use_crf\n","        self.rnn_layers: int = rnn_layers\n","\n","        self.trained_epochs: int = 0\n","\n","        self.embeddings = embeddings\n","\n","        # set the dictionaries\n","        self.tag_dictionary: Dictionary = tag_dictionary\n","        self.tag_type: str = tag_type\n","        self.tagset_size: int = len(tag_dictionary)\n","\n","        self.beta = beta\n","\n","        self.weight_dict = loss_weights\n","        # Initialize the weight tensor\n","        if loss_weights is not None:\n","            n_classes = len(self.tag_dictionary)\n","            weight_list = [1. for i in range(n_classes)]\n","            for i, tag in enumerate(self.tag_dictionary.get_items()):\n","                if tag in loss_weights.keys():\n","                    weight_list[i] = loss_weights[tag]\n","            self.loss_weights = torch.FloatTensor(weight_list).to(flair.device)\n","        else:\n","            self.loss_weights = None\n","\n","        # initialize the network architecture\n","        self.nlayers: int = rnn_layers\n","        self.hidden_word = None\n","\n","        # dropouts\n","        self.use_dropout: float = dropout\n","        self.use_word_dropout: float = word_dropout\n","        self.use_locked_dropout: float = locked_dropout\n","\n","        self.pickle_module = pickle_module\n","\n","        if dropout > 0.0:\n","            self.dropout = torch.nn.Dropout(dropout)\n","\n","        if word_dropout > 0.0:\n","            self.word_dropout = flair.nn.WordDropout(word_dropout)\n","\n","        if locked_dropout > 0.0:\n","            self.locked_dropout = flair.nn.LockedDropout(locked_dropout)\n","\n","        rnn_input_dim: int = self.embeddings.embedding_length\n","\n","        self.relearn_embeddings: bool = True\n","\n","        if self.relearn_embeddings:\n","            self.embedding2nn = BF(rnn_input_dim, nn_input_dim)\n","            print (\"apperntly embedding\")\n","\n","        self.train_initial_hidden_state = train_initial_hidden_state\n","        self.bidirectional = True\n","        self.rnn_type = rnn_type\n","\n","        # bidirectional LSTM on top of embedding layer\n","        if self.use_rnn:\n","            num_directions = 2 if self.bidirectional else 1\n","\n","            if self.rnn_type in [\"LSTM\", \"GRU\"]:\n","\n","                self.rnn = getattr(torch.nn, self.rnn_type)(\n","                    rnn_input_dim,\n","                    hidden_size,\n","                    num_layers=self.nlayers,\n","                    dropout=0.0 if self.nlayers == 1 else 0.5,\n","                    bidirectional=True,\n","                    batch_first=True,\n","                )\n","                # Create initial hidden state and initialize it\n","                if self.train_initial_hidden_state:\n","                    self.hs_initializer = torch.nn.init.xavier_normal_\n","\n","                    self.lstm_init_h = Parameter(\n","                        torch.randn(self.nlayers * num_directions, self.hidden_size),\n","                        requires_grad=True,\n","                    )\n","\n","                    self.lstm_init_c = Parameter(\n","                        torch.randn(self.nlayers * num_directions, self.hidden_size),\n","                        requires_grad=True,\n","                    )\n","\n","                    # TODO: Decide how to initialize the hidden state variables\n","                    # self.hs_initializer(self.lstm_init_h)\n","                    # self.hs_initializer(self.lstm_init_c)\n","\n","            # final linear map to tag space\n","            self.linear = BF(hidden_size * num_directions, en(tag_dictionary))\n","            print (\"if not else\")\n","        else:\n","            #self.linear = torch.nn.Linear(\n","            #    self.embeddings.embedding_length, len(tag_dictionary)\n","           # )\n","            self.linear = BF(self.embeddings.embedding_length, len(tag_dictionary))\n","            print (\"else not if \")\n","\n","        if self.use_crf:\n","            self.transitions = torch.nn.Parameter(\n","                torch.randn(self.tagset_size, self.tagset_size)\n","            )\n","\n","            self.transitions.detach()[\n","                self.tag_dictionary.get_idx_for_item(START_TAG), :\n","            ] = -10000\n","\n","            self.transitions.detach()[\n","                :, self.tag_dictionary.get_idx_for_item(STOP_TAG)\n","            ] = -10000\n","\n","        self.to(flair.device)\n","\n","    def _get_state_dict(self):\n","        model_state = {\n","            \"state_dict\": self.state_dict(),\n","            \"embeddings\": self.embeddings,\n","            \"hidden_size\": self.hidden_size,\n","            \"train_initial_hidden_state\": self.train_initial_hidden_state,\n","            \"tag_dictionary\": self.tag_dictionary,\n","            \"tag_type\": self.tag_type,\n","            \"use_crf\": self.use_crf,\n","            \"use_rnn\": self.use_rnn,\n","            \"rnn_layers\": self.rnn_layers,\n","            \"use_word_dropout\": self.use_word_dropout,\n","            \"use_locked_dropout\": self.use_locked_dropout,\n","            \"rnn_type\": self.rnn_type,\n","            \"beta\": self.beta,\n","            \"weight_dict\": self.weight_dict,\n","        }\n","        return model_state\n","\n","    @staticmethod\n","    def _init_model_with_state_dict(state):\n","\n","        rnn_type = \"LSTM\" if \"rnn_type\" not in state.keys() else state[\"rnn_type\"]\n","        use_dropout = 0.0 if \"use_dropout\" not in state.keys() else state[\"use_dropout\"]\n","        use_word_dropout = (\n","            0.0 if \"use_word_dropout\" not in state.keys() else state[\"use_word_dropout\"]\n","        )\n","        use_locked_dropout = (\n","            0.0\n","            if \"use_locked_dropout\" not in state.keys()\n","            else state[\"use_locked_dropout\"]\n","        )\n","        train_initial_hidden_state = (\n","            False\n","            if \"train_initial_hidden_state\" not in state.keys()\n","            else state[\"train_initial_hidden_state\"]\n","        )\n","        beta = 1.0 if \"beta\" not in state.keys() else state[\"beta\"]\n","        weights = None if \"weight_dict\" not in state.keys() else state[\"weight_dict\"]\n","\n","        model = SequenceTaggerBF(\n","            hidden_size=state[\"hidden_size\"],\n","            embeddings=state[\"embeddings\"],\n","            tag_dictionary=state[\"tag_dictionary\"],\n","            tag_type=state[\"tag_type\"],\n","            use_crf=state[\"use_crf\"],\n","            use_rnn=state[\"use_rnn\"],\n","            rnn_layers=state[\"rnn_layers\"],\n","            dropout=use_dropout,\n","            word_dropout=use_word_dropout,\n","            locked_dropout=use_locked_dropout,\n","            train_initial_hidden_state=train_initial_hidden_state,\n","            rnn_type=rnn_type,\n","            beta=beta,\n","            loss_weights=weights,\n","        )\n","        model.load_state_dict(state[\"state_dict\"])\n","        return model\n","\n","    def predict(\n","        self,\n","        sentences: Union[List[Sentence], Sentence, List[str], str],\n","        mini_batch_size=32,\n","        embedding_storage_mode=\"none\",\n","        all_tag_prob: bool = False,\n","        verbose: bool = False,\n","        use_tokenizer: Union[bool, Callable[[str], List[Token]]] = space_tokenizer,\n","    ) -> List[Sentence]:\n","        \"\"\"\n","        Predict sequence tags for Named Entity Recognition task\n","        :param sentences: a Sentence or a string or a List of Sentence or a List of string.\n","        :param mini_batch_size: size of the minibatch, usually bigger is more rapid but consume more memory,\n","        up to a point when it has no more effect.\n","        :param embedding_storage_mode: 'none' for the minimum memory footprint, 'cpu' to store embeddings in Ram,\n","        'gpu' to store embeddings in GPU memory.\n","        :param all_tag_prob: True to compute the score for each tag on each token,\n","        otherwise only the score of the best tag is returned\n","        :param verbose: set to True to display a progress bar\n","        :param use_tokenizer: a custom tokenizer when string are provided (default is space based tokenizer).\n","        :return: List of Sentence enriched by the predicted tags\n","        \"\"\"\n","        with torch.no_grad():\n","            if not sentences:\n","                return sentences\n","\n","            if isinstance(sentences, Sentence) or isinstance(sentences, str):\n","                sentences = [sentences]\n","\n","            if (flair.device.type == \"cuda\") and embedding_storage_mode == \"cpu\":\n","                log.warning(\n","                    \"You are inferring on GPU with parameter 'embedding_storage_mode' set to 'cpu'.\"\n","                    \"This option will slow down your inference, usually 'none' (default value) \"\n","                    \"is a better choice.\"\n","                )\n","\n","            # reverse sort all sequences by their length\n","            rev_order_len_index = sorted(\n","                range(len(sentences)), key=lambda k: len(sentences[k]), reverse=True\n","            )\n","            original_order_index = sorted(\n","                range(len(rev_order_len_index)), key=lambda k: rev_order_len_index[k]\n","            )\n","\n","            reordered_sentences: List[Union[Sentence, str]] = [\n","                sentences[index] for index in rev_order_len_index\n","            ]\n","\n","            if isinstance(sentences[0], Sentence):\n","                # remove previous embeddings\n","                store_embeddings(reordered_sentences, \"none\")\n","                dataset = SentenceDataset(reordered_sentences)\n","            else:\n","                dataset = StringDataset(\n","                    reordered_sentences, use_tokenizer=use_tokenizer\n","                )\n","            dataloader = DataLoader(\n","                dataset=dataset, batch_size=mini_batch_size, collate_fn=lambda x: x\n","            )\n","\n","            if self.use_crf:\n","                transitions = self.transitions.detach().cpu().numpy()\n","            else:\n","                transitions = None\n","\n","            # progress bar for verbosity\n","            if verbose:\n","                dataloader = tqdm(dataloader)\n","\n","            results: List[Sentence] = []\n","            for i, batch in enumerate(dataloader):\n","\n","                if verbose:\n","                    dataloader.set_description(f\"Inferencing on batch {i}\")\n","                results += batch\n","                batch = self._filter_empty_sentences(batch)\n","                # stop if all sentences are empty\n","                if not batch:\n","                    continue\n","\n","                feature: torch.Tensor = self.forward(batch)\n","                tags, all_tags = self._obtain_labels(\n","                    feature=feature,\n","                    batch_sentences=batch,\n","                    transitions=transitions,\n","                    get_all_tags=all_tag_prob,\n","                )\n","\n","                for (sentence, sent_tags) in zip(batch, tags):\n","                    for (token, tag) in zip(sentence.tokens, sent_tags):\n","                        token.add_tag_label(self.tag_type, tag)\n","\n","                # all_tags will be empty if all_tag_prob is set to False, so the for loop will be avoided\n","                for (sentence, sent_all_tags) in zip(batch, all_tags):\n","                    for (token, token_all_tags) in zip(sentence.tokens, sent_all_tags):\n","                        token.add_tags_proba_dist(self.tag_type, token_all_tags)\n","\n","                # clearing token embeddings to save memory\n","                store_embeddings(batch, storage_mode=embedding_storage_mode)\n","\n","            results: List[Union[Sentence, str]] = [\n","                results[index] for index in original_order_index\n","            ]\n","            assert len(sentences) == len(results)\n","            return results\n","\n","    def evaluate(\n","        self,\n","        data_loader: DataLoader,\n","        out_path: Path = None,\n","        embedding_storage_mode: str = \"none\",\n","    ) -> (Result, float):\n","\n","        if type(out_path) == str:\n","            out_path = Path(out_path)\n","\n","        with torch.no_grad():\n","            eval_loss = 0\n","\n","            batch_no: int = 0\n","\n","            metric = Metric(\"Evaluation\", beta=self.beta)\n","\n","            lines: List[str] = []\n","\n","            if self.use_crf:\n","                transitions = self.transitions.detach().cpu().numpy()\n","            else:\n","                transitions = None\n","\n","            for batch in data_loader:\n","                batch_no += 1\n","\n","                with torch.no_grad():\n","                    features = self.forward(batch)\n","                    loss = self._calculate_loss(features, batch)\n","                    tags, _ = self._obtain_labels(\n","                        feature=features,\n","                        batch_sentences=batch,\n","                        transitions=transitions,\n","                        get_all_tags=False,\n","                    )\n","\n","                eval_loss += loss\n","\n","                for (sentence, sent_tags) in zip(batch, tags):\n","                    for (token, tag) in zip(sentence.tokens, sent_tags):\n","                        token: Token = token\n","                        token.add_tag(\"predicted\", tag.value, tag.score)\n","\n","                        # append both to file for evaluation\n","                        eval_line = \"{} {} {} {}\\n\".format(\n","                            token.text,\n","                            token.get_tag(self.tag_type).value,\n","                            tag.value,\n","                            tag.score,\n","                        )\n","                        lines.append(eval_line)\n","                    lines.append(\"\\n\")\n","\n","                for sentence in batch:\n","                    # make list of gold tags\n","                    gold_tags = [\n","                        (tag.tag, tag.text) for tag in sentence.get_spans(self.tag_type)\n","                    ]\n","                    # make list of predicted tags\n","                    predicted_tags = [\n","                        (tag.tag, tag.text) for tag in sentence.get_spans(\"predicted\")\n","                    ]\n","\n","                    # check for true positives, false positives and false negatives\n","                    for tag, prediction in predicted_tags:\n","                        if (tag, prediction) in gold_tags:\n","                            metric.add_tp(tag)\n","                        else:\n","                            metric.add_fp(tag)\n","\n","                    for tag, gold in gold_tags:\n","                        if (tag, gold) not in predicted_tags:\n","                            metric.add_fn(tag)\n","                        else:\n","                            metric.add_tn(tag)\n","\n","                store_embeddings(batch, embedding_storage_mode)\n","\n","            eval_loss /= batch_no\n","\n","            if out_path is not None:\n","                with open(out_path, \"w\", encoding=\"utf-8\") as outfile:\n","                    outfile.write(\"\".join(lines))\n","\n","            detailed_result = (\n","                f\"\\nMICRO_AVG: acc {metric.micro_avg_accuracy():.4f} - f1-score {metric.micro_avg_f_score():.4f}\"\n","                f\"\\nMACRO_AVG: acc {metric.macro_avg_accuracy():.4f} - f1-score {metric.macro_avg_f_score():.4f}\"\n","            )\n","            for class_name in metric.get_classes():\n","                detailed_result += (\n","                    f\"\\n{class_name:<10} tp: {metric.get_tp(class_name)} - fp: {metric.get_fp(class_name)} - \"\n","                    f\"fn: {metric.get_fn(class_name)} - tn: {metric.get_tn(class_name)} - precision: \"\n","                    f\"{metric.precision(class_name):.4f} - recall: {metric.recall(class_name):.4f} - \"\n","                    f\"accuracy: {metric.accuracy(class_name):.4f} - f1-score: \"\n","                    f\"{metric.f_score(class_name):.4f}\"\n","                )\n","\n","            result = Result(\n","                main_score=metric.micro_avg_f_score(),\n","                log_line=f\"{metric.precision():.4f}\\t{metric.recall():.4f}\\t{metric.micro_avg_f_score():.4f}\",\n","                log_header=\"PRECISION\\tRECALL\\tF1\",\n","                detailed_results=detailed_result,\n","            )\n","\n","            return result, eval_loss\n","\n","    def forward_loss(\n","        self, data_points: Union[List[Sentence], Sentence], sort=True\n","    ) -> torch.tensor:\n","        features = self.forward(data_points)\n","        return self._calculate_loss(features, data_points)\n","\n","    def forward(self, sentences: List[Sentence]):\n","\n","        self.embeddings.embed(sentences)\n","\n","        lengths: List[int] = [len(sentence.tokens) for sentence in sentences]\n","        longest_token_sequence_in_batch: int = max(lengths)\n","\n","        pre_allocated_zero_tensor = torch.zeros(\n","            self.embeddings.embedding_length * longest_token_sequence_in_batch,\n","            dtype=torch.float,\n","            device=flair.device,\n","        )\n","\n","        all_embs = list()\n","        for sentence in sentences:\n","            all_embs += [\n","                emb for token in sentence for emb in token.get_each_embedding()\n","            ]\n","            nb_padding_tokens = longest_token_sequence_in_batch - len(sentence)\n","\n","            if nb_padding_tokens > 0:\n","                t = pre_allocated_zero_tensor[\n","                    : self.embeddings.embedding_length * nb_padding_tokens\n","                ]\n","                all_embs.append(t)\n","\n","        sentence_tensor = torch.cat(all_embs).view(\n","            [\n","                len(sentences),\n","                longest_token_sequence_in_batch,\n","                self.embeddings.embedding_length,\n","            ]\n","        )\n","\n","        # --------------------------------------------------------------------\n","        # FF PART\n","        # --------------------------------------------------------------------\n","        if self.use_dropout > 0.0:\n","            sentence_tensor = self.dropout(sentence_tensor)\n","        if self.use_word_dropout > 0.0:\n","            sentence_tensor = self.word_dropout(sentence_tensor)\n","        if self.use_locked_dropout > 0.0:\n","            sentence_tensor = self.locked_dropout(sentence_tensor)\n","\n","        if self.relearn_embeddings:\n","            print (sentence_tensor.shape)\n","            sentence_tensor = self.embedding2nn(sentence_tensor)\n","\n","        if self.use_rnn:\n","            packed = torch.nn.utils.rnn.pack_padded_sequence(\n","                sentence_tensor, lengths, enforce_sorted=False, batch_first=True\n","            )\n","\n","            # if initial hidden state is trainable, use this state\n","            if self.train_initial_hidden_state:\n","                initial_hidden_state = [\n","                    self.lstm_init_h.unsqueeze(1).repeat(1, len(sentences), 1),\n","                    self.lstm_init_c.unsqueeze(1).repeat(1, len(sentences), 1),\n","                ]\n","                rnn_output, hidden = self.rnn(packed, initial_hidden_state)\n","            else:\n","                rnn_output, hidden = self.rnn(packed)\n","\n","            sentence_tensor, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n","                rnn_output, batch_first=True\n","            )\n","\n","            if self.use_dropout > 0.0:\n","                sentence_tensor = self.dropout(sentence_tensor)\n","            # word dropout only before LSTM - TODO: more experimentation needed\n","            # if self.use_word_dropout > 0.0:\n","            #     sentence_tensor = self.word_dropout(sentence_tensor)\n","            if self.use_locked_dropout > 0.0:\n","                sentence_tensor = self.locked_dropout(sentence_tensor)\n","        print (sentence_tensor.shape)\n","        print (sentence_tensor)\n","        features = self.linear(sentence_tensor)\n","\n","        return features\n","\n","    def _score_sentence(self, feats, tags, lens_):\n","\n","        start = torch.tensor(\n","            [self.tag_dictionary.get_idx_for_item(START_TAG)], device=flair.device\n","        )\n","        start = start[None, :].repeat(tags.shape[0], 1)\n","\n","        stop = torch.tensor(\n","            [self.tag_dictionary.get_idx_for_item(STOP_TAG)], device=flair.device\n","        )\n","        stop = stop[None, :].repeat(tags.shape[0], 1)\n","\n","        pad_start_tags = torch.cat([start, tags], 1)\n","        pad_stop_tags = torch.cat([tags, stop], 1)\n","\n","        for i in range(len(lens_)):\n","            pad_stop_tags[i, lens_[i] :] = self.tag_dictionary.get_idx_for_item(\n","                STOP_TAG\n","            )\n","\n","        score = torch.FloatTensor(feats.shape[0]).to(flair.device)\n","\n","        for i in range(feats.shape[0]):\n","            r = torch.LongTensor(range(lens_[i])).to(flair.device)\n","\n","            score[i] = torch.sum(\n","                self.transitions[\n","                    pad_stop_tags[i, : lens_[i] + 1], pad_start_tags[i, : lens_[i] + 1]\n","                ]\n","            ) + torch.sum(feats[i, r, tags[i, : lens_[i]]])\n","\n","        return score\n","\n","    def _calculate_loss(\n","        self, features: torch.tensor, sentences: List[Sentence]\n","    ) -> float:\n","\n","        lengths: List[int] = [len(sentence.tokens) for sentence in sentences]\n","\n","        tag_list: List = []\n","        for s_id, sentence in enumerate(sentences):\n","            # get the tags in this sentence\n","            tag_idx: List[int] = [\n","                self.tag_dictionary.get_idx_for_item(token.get_tag(self.tag_type).value)\n","                for token in sentence\n","            ]\n","            # add tags as tensor\n","            tag = torch.tensor(tag_idx, device=flair.device)\n","            tag_list.append(tag)\n","\n","        if self.use_crf:\n","            # pad tags if using batch-CRF decoder\n","            tags, _ = pad_tensors(tag_list)\n","\n","            forward_score = self._forward_alg(features, lengths)\n","            gold_score = self._score_sentence(features, tags, lengths)\n","            score = forward_score - gold_score\n","            return score.mean()\n","        else:\n","            score = 0\n","            for sentence_feats, sentence_tags, sentence_length in zip(\n","                features, tag_list, lengths\n","            ):\n","                sentence_feats = sentence_feats[:sentence_length]\n","                score += torch.nn.functional.cross_entropy(\n","                    sentence_feats, sentence_tags, weight=self.loss_weights\n","                )\n","            score /= len(features)\n","            return score\n","    def _obtain_labels(\n","        self,\n","        feature: torch.Tensor,\n","        batch_sentences: List[Sentence],\n","        transitions: Optional[np.ndarray],\n","        get_all_tags: bool,\n","    ) -> (List[List[Label]], List[List[List[Label]]]):\n","        \"\"\"\n","        Returns a tuple of two lists:\n","         - The first list corresponds to the most likely `Label` per token in each sentence.\n","         - The second list contains a probability distribution over all `Labels` for each token\n","           in a sentence for all sentences.\n","        \"\"\"\n","\n","        lengths: List[int] = [len(sentence.tokens) for sentence in batch_sentences]\n","\n","        tags = []\n","        all_tags = []\n","        feature = feature.cpu()\n","        if self.use_crf:\n","            feature = feature.numpy()\n","        else:\n","            for index, length in enumerate(lengths):\n","                feature[index, length:] = 0\n","            softmax_batch = F.softmax(feature, dim=2).cpu()\n","            scores_batch, prediction_batch = torch.max(softmax_batch, dim=2)\n","            feature = zip(softmax_batch, scores_batch, prediction_batch)\n","\n","        for feats, length in zip(feature, lengths):\n","            if self.use_crf:\n","                confidences, tag_seq, scores = self._viterbi_decode(\n","                    feats=feats[:length],\n","                    transitions=transitions,\n","                    all_scores=get_all_tags,\n","                )\n","            else:\n","                softmax, score, prediction = feats\n","                confidences = score[:length].tolist()\n","                tag_seq = prediction[:length].tolist()\n","                scores = softmax[:length].tolist()\n","\n","            tags.append(\n","                [\n","                    Label(self.tag_dictionary.get_item_for_index(tag), conf)\n","                    for conf, tag in zip(confidences, tag_seq)\n","                ]\n","            )\n","\n","            if get_all_tags:\n","                all_tags.append(\n","                    [\n","                        [\n","                            Label(\n","                                self.tag_dictionary.get_item_for_index(score_id), score\n","                            )\n","                            for score_id, score in enumerate(score_dist)\n","                        ]\n","                        for score_dist in scores\n","                    ]\n","                )\n","\n","        return tags, all_tags\n","\n","    @staticmethod\n","    def _softmax(x, axis):\n","        # reduce raw values to avoid NaN during exp\n","        x_norm = x - x.max(axis=axis, keepdims=True)\n","        y = np.exp(x_norm)\n","        return y / y.sum(axis=axis, keepdims=True)\n","\n","    def _viterbi_decode(\n","        self, feats: np.ndarray, transitions: np.ndarray, all_scores: bool\n","    ):\n","        id_start = self.tag_dictionary.get_idx_for_item(START_TAG)\n","        id_stop = self.tag_dictionary.get_idx_for_item(STOP_TAG)\n","\n","        backpointers = np.empty(shape=(feats.shape[0], self.tagset_size), dtype=np.int_)\n","        backscores = np.empty(\n","            shape=(feats.shape[0], self.tagset_size), dtype=np.float32\n","        )\n","\n","        init_vvars = np.expand_dims(\n","            np.repeat(-10000.0, self.tagset_size), axis=0\n","        ).astype(np.float32)\n","        init_vvars[0][id_start] = 0\n","\n","        forward_var = init_vvars\n","        for index, feat in enumerate(feats):\n","            # broadcasting will do the job of reshaping and is more efficient than calling repeat\n","            next_tag_var = forward_var + transitions\n","            bptrs_t = next_tag_var.argmax(axis=1)\n","            viterbivars_t = next_tag_var[np.arange(bptrs_t.shape[0]), bptrs_t]\n","            forward_var = viterbivars_t + feat\n","            backscores[index] = forward_var\n","            forward_var = forward_var[np.newaxis, :]\n","            backpointers[index] = bptrs_t\n","\n","        terminal_var = forward_var.squeeze() + transitions[id_stop]\n","        terminal_var[id_stop] = -10000.0\n","        terminal_var[id_start] = -10000.0\n","        best_tag_id = terminal_var.argmax()\n","\n","        best_path = [best_tag_id]\n","        for bptrs_t in reversed(backpointers):\n","            best_tag_id = bptrs_t[best_tag_id]\n","            best_path.append(best_tag_id)\n","\n","        start = best_path.pop()\n","        assert start == id_start\n","        best_path.reverse()\n","\n","        best_scores_softmax = self._softmax(backscores, axis=1)\n","        best_scores_np = np.max(best_scores_softmax, axis=1)\n","\n","        # default value\n","        all_scores_np = np.zeros(0, dtype=np.float64)\n","        if all_scores:\n","            all_scores_np = best_scores_softmax\n","            for index, (tag_id, tag_scores) in enumerate(zip(best_path, all_scores_np)):\n","                if type(tag_id) != int and tag_id.item() != tag_scores.argmax():\n","                    swap_index_score = tag_scores.argmax()\n","                    (\n","                        all_scores_np[index][tag_id.item()],\n","                        all_scores_np[index][swap_index_score],\n","                    ) = (\n","                        all_scores_np[index][swap_index_score],\n","                        all_scores_np[index][tag_id.item()],\n","                    )\n","                elif type(tag_id) == int and tag_id != tag_scores.argmax():\n","                    swap_index_score = tag_scores.argmax()\n","                    (\n","                        all_scores_np[index][tag_id],\n","                        all_scores_np[index][swap_index_score],\n","                    ) = (\n","                        all_scores_np[index][swap_index_score],\n","                        all_scores_np[index][tag_id],\n","                    )\n","\n","        return best_scores_np.tolist(), best_path, all_scores_np.tolist()\n","\n","    def _forward_alg(self, feats, lens_):\n","\n","        init_alphas = torch.FloatTensor(self.tagset_size).fill_(-10000.0)\n","        init_alphas[self.tag_dictionary.get_idx_for_item(START_TAG)] = 0.0\n","\n","        forward_var = torch.zeros(\n","            feats.shape[0],\n","            feats.shape[1] + 1,\n","            feats.shape[2],\n","            dtype=torch.float,\n","            device=flair.device,\n","        )\n","\n","        forward_var[:, 0, :] = init_alphas[None, :].repeat(feats.shape[0], 1)\n","\n","        transitions = self.transitions.view(\n","            1, self.transitions.shape[0], self.transitions.shape[1]\n","        ).repeat(feats.shape[0], 1, 1)\n","\n","        for i in range(feats.shape[1]):\n","            emit_score = feats[:, i, :]\n","\n","            tag_var = (\n","                emit_score[:, :, None].repeat(1, 1, transitions.shape[2])\n","                + transitions\n","                + forward_var[:, i, :][:, :, None]\n","                .repeat(1, 1, transitions.shape[2])\n","                .transpose(2, 1)\n","            )\n","\n","            max_tag_var, _ = torch.max(tag_var, dim=2)\n","\n","            tag_var = tag_var - max_tag_var[:, :, None].repeat(\n","                1, 1, transitions.shape[2]\n","            )\n","\n","            agg_ = torch.log(torch.sum(torch.exp(tag_var), dim=2))\n","\n","            cloned = forward_var.clone()\n","            cloned[:, i + 1, :] = max_tag_var + agg_\n","\n","            forward_var = cloned\n","\n","        forward_var = forward_var[range(forward_var.shape[0]), lens_, :]\n","\n","        terminal_var = forward_var + self.transitions[\n","            self.tag_dictionary.get_idx_for_item(STOP_TAG)\n","        ][None, :].repeat(forward_var.shape[0], 1)\n","        alpha = log_sum_exp_batch(terminal_var)\n","        return alpha\n","    @staticmethod\n","    def _filter_empty_sentences(sentences: List[Sentence]) -> List[Sentence]:\n","        filtered_sentences = [sentence for sentence in sentences if sentence.tokens]\n","        if len(sentences) != len(filtered_sentences):\n","            log.warning(\n","                f\"Ignore {len(sentences) - len(filtered_sentences)} sentence(s) with no tokens.\"\n","            )\n","        return filtered_sentences\n","\n","    @staticmethod\n","    def _filter_empty_string(texts: List[str]) -> List[str]:\n","        filtered_texts = [text for text in texts if text]\n","        if len(texts) != len(filtered_texts):\n","            log.warning(\n","                f\"Ignore {len(texts) - len(filtered_texts)} string(s) with no tokens.\"\n","            )\n","        return filtered_texts\n","    @staticmethod\n","    def _fetch_model(model_name) -> str:\n","        model_map = {}\n","        aws_resource_path_v04 = (\n","            \"https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4\"\n","        )\n","\n","        model_map[\"ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"NER-conll03-english\", \"en-ner-conll03-v0.4.pt\"]\n","        )\n","\n","        model_map[\"ner-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"NER-conll03--h256-l1-b32-p3-0.5-%2Bglove%2Bnews-forward-fast%2Bnews-backward-fast-normal-locked0.5-word0.05--release_4\",\n","                \"en-ner-fast-conll03-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"ner-ontonotes\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-ner-ontonotes-0\",\n","                \"en-ner-ontonotes-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"ner-ontonotes-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-ner-ontonotes-fast-0\",\n","                \"en-ner-ontonotes-fast-v0.4.pt\",\n","            ]\n","        )\n","        for key in [\"ner-multi\", \"multi-ner\"]:\n","            model_map[key] = \"/\".join(\n","                [\n","                    aws_resource_path_v04,\n","                    \"release-quadner-512-l2-multi-embed\",\n","                    \"quadner-large.pt\",\n","                ]\n","            )\n","        for key in [\"ner-multi-fast\", \"multi-ner-fast\"]:\n","            model_map[key] = \"/\".join(\n","                [aws_resource_path_v04, \"NER-multi-fast\", \"ner-multi-fast.pt\"]\n","            )\n","        for key in [\"ner-multi-fast-learn\", \"multi-ner-fast-learn\"]:\n","            model_map[key] = \"/\".join(\n","                [\n","                    aws_resource_path_v04,\n","                    \"NER-multi-fast-evolve\",\n","                    \"ner-multi-fast-learn.pt\",\n","                ]\n","            )\n","        model_map[\"pos\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"POS-ontonotes--h256-l1-b32-p3-0.5-%2Bglove%2Bnews-forward%2Bnews-backward-normal-locked0.5-word0.05--v0.4_0\",\n","                \"en-pos-ontonotes-v0.4.pt\",\n","            ]\n","        )\n","\n","        model_map[\"pos-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-pos-fast-0\",\n","                \"en-pos-ontonotes-fast-v0.4.pt\",\n","            ]\n","        )\n","        for key in [\"pos-multi\", \"multi-pos\"]:\n","            model_map[key] = \"/\".join(\n","                [\n","                    aws_resource_path_v04,\n","                    \"release-dodekapos-512-l2-multi\",\n","                    \"pos-multi-v0.1.pt\",\n","                ]\n","            )\n","        for key in [\"pos-multi-fast\", \"multi-pos-fast\"]:\n","            model_map[key] = \"/\".join(\n","                [aws_resource_path_v04, \"UPOS-multi-fast\", \"pos-multi-fast.pt\"]\n","            )\n","        model_map[\"frame\"] = \"/\".join(\n","            [aws_resource_path_v04, \"release-frame-1\", \"en-frame-ontonotes-v0.4.pt\"]\n","        )\n","\n","        model_map[\"frame-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-frame-fast-0\",\n","                \"en-frame-ontonotes-fast-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"chunk\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"NP-conll2000--h256-l1-b32-p3-0.5-%2Bnews-forward%2Bnews-backward-normal-locked0.5-word0.05--v0.4_0\",\n","                \"en-chunk-conll2000-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"chunk-fast\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"release-chunk-fast-0\",\n","                \"en-chunk-conll2000-fast-v0.4.pt\",\n","            ]\n","        )\n","        model_map[\"da-pos\"] = \"/\".join(\n","            [aws_resource_path_v04, \"POS-danish\", \"da-pos-v0.1.pt\"]\n","        )\n","\n","        model_map[\"da-ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"NER-danish\", \"da-ner-v0.1.pt\"]\n","        )\n","\n","        model_map[\"de-pos\"] = \"/\".join(\n","            [aws_resource_path_v04, \"release-de-pos-0\", \"de-pos-ud-hdt-v0.4.pt\"]\n","        )\n","        model_map[\"de-pos-fine-grained\"] = \"/\".join(\n","            [\n","                aws_resource_path_v04,\n","                \"POS-fine-grained-german-tweets\",\n","                \"de-pos-twitter-v0.1.pt\",\n","            ]\n","        )\n","        model_map[\"de-ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"release-de-ner-0\", \"de-ner-conll03-v0.4.pt\"]\n","        )\n","\n","        model_map[\"de-ner-germeval\"] = \"/\".join(\n","            [aws_resource_path_v04, \"NER-germeval\", \"de-ner-germeval-0.4.1.pt\"]\n","        )\n","\n","        model_map[\"fr-ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"release-fr-ner-0\", \"fr-ner-wikiner-0.4.pt\"]\n","        )\n","        model_map[\"nl-ner\"] = \"/\".join(\n","            [aws_resource_path_v04, \"NER-conll2002-dutch\", \"nl-ner-conll02-v0.1.pt\"]\n","        )\n","        model_map[\"ml-pos\"] = \"https://raw.githubusercontent.com/qburst/models-repository/master/FlairMalayalamModels/malayalam-upos-model.pt\"\n","        model_map[\"ml-xpos\"] = \"https://raw.githubusercontent.com/qburst/models-repository/master/FlairMalayalamModels/malayalam-xpos-model.pt\"\n","\n","        cache_dir = Path(\"models\")\n","        if model_name in model_map:\n","            model_name = cached_path(model_map[model_name], cache_dir=cache_dir)\n","        # the historical German taggers by the @redewiegergabe project\n","        if model_name == \"de-historic-indirect\":\n","            model_file = Path(flair.cache_root)  / cache_dir / 'indirect' / 'final-model.pt'\n","            if not model_file.exists():\n","                cached_path('http://www.redewiedergabe.de/models/indirect.zip', cache_dir=cache_dir)\n","                unzip_file(Path(flair.cache_root)  / cache_dir / 'indirect.zip', Path(flair.cache_root)  / cache_dir)\n","            model_name = str(Path(flair.cache_root)  / cache_dir / 'indirect' / 'final-model.pt')\n","\n","        if model_name == \"de-historic-direct\":\n","            model_file = Path(flair.cache_root)  / cache_dir / 'direct' / 'final-model.pt'\n","            if not model_file.exists():\n","                cached_path('http://www.redewiedergabe.de/models/direct.zip', cache_dir=cache_dir)\n","                unzip_file(Path(flair.cache_root)  / cache_dir / 'direct.zip', Path(flair.cache_root)  / cache_dir)\n","            model_name = str(Path(flair.cache_root)  / cache_dir / 'direct' / 'final-model.pt')\n","\n","        if model_name == \"de-historic-reported\":\n","            model_file = Path(flair.cache_root)  / cache_dir / 'reported' / 'final-model.pt'\n","            if not model_file.exists():\n","                cached_path('http://www.redewiedergabe.de/models/reported.zip', cache_dir=cache_dir)\n","                unzip_file(Path(flair.cache_root)  / cache_dir / 'reported.zip', Path(flair.cache_root)  / cache_dir)\n","            model_name = str(Path(flair.cache_root)  / cache_dir / 'reported' / 'final-model.pt')\n","\n","        if model_name == \"de-historic-free-indirect\":\n","            model_file = Path(flair.cache_root)  / cache_dir / 'freeIndirect' / 'final-model.pt'\n","            if not model_file.exists():\n","                cached_path('http://www.redewiedergabe.de/models/freeIndirect.zip', cache_dir=cache_dir)\n","                unzip_file(Path(flair.cache_root)  / cache_dir / 'freeIndirect.zip', Path(flair.cache_root)  / cache_dir)\n","            model_name = str(Path(flair.cache_root)  / cache_dir / 'freeIndirect' / 'final-model.pt')\n","\n","        return model_name\n","    def get_transition_matrix(self):\n","        data = []\n","        for to_idx, row in enumerate(self.transitions):\n","            for from_idx, column in enumerate(row):\n","                row = [\n","                    self.tag_dictionary.get_item_for_index(from_idx),\n","                    self.tag_dictionary.get_item_for_index(to_idx),\n","                    column.item(),\n","                ]\n","                data.append(row)\n","            data.append([\"----\"])\n","        print(tabulate(data, headers=[\"FROM\", \"TO\", \"SCORE\"]))\n","    def __str__(self):\n","        return super(flair.nn.Model, self).__str__().rstrip(')') + \\\n","               f'  (beta): {self.beta}\\n' + \\\n","               f'  (weights): {self.weight_dict}\\n' + \\\n","               f'  (weight_tensor) {self.loss_weights}\\n)'"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'AutoModel' from 'transformers' (/home/mmm/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4cd55b42a490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/flair/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrainers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/flair/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msequence_tagger_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlanguage_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtext_classification_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtext_classification_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextPairClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStackedEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munzip_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/flair/embeddings/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Expose token embedding classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackedEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbpemb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBPEmb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoModel' from 'transformers' (/home/mmm/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/__init__.py)"]}]},{"cell_type":"code","metadata":{"id":"4s0T_utDiKH_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gfRIZ1WaiKH_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CrLx1PgKiKH_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jM1SxP-3iKH_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2X7YrXRyiKH_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_I9YIuRpiKH_"},"source":[""],"execution_count":null,"outputs":[]}]}